{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giacomoarienti/data-intensive-lab/blob/master/BBS_TextMining_Lab4_Finetuning_Prompting_LLMs_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3adf1fb"
      },
      "source": [
        "# Automatic Text Summarization: Fine-tuning and Prompting with Small & Large Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdpaeR4pLKAQ"
      },
      "source": [
        "**Text Mining unit**\n",
        "\n",
        "_Prof. Gianluca Moro, Dott. Luca Ragazzi, Dott. Lorenzo Molfetta ‚Äì DISI, University of Bologna_\n",
        "\n",
        "Alma Mater Studiorum Universit√† di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YjmKMCoMS_x"
      },
      "source": [
        "## üìú Outline\n",
        "\n",
        "- [ 0 - Setup Kernel and Required Dependencies](#0)\n",
        "- [ 1 - Brief Introduction on Automatic Text Summarization](#1)\n",
        "    - [ 1.1 - Extractive Summarization](#1.1)\n",
        "    - [ 1.2 - Abstractive Summarization](#1.2)\n",
        "- [ 2 - Understand How Language Models Work](#2)\n",
        "    - [ 2.1 - Load the Model](#2.1)\n",
        "    - [ 2.2 - What's the Input like?](#2.2)\n",
        "    - [ 2.3 - What About the Output?](#2.3)\n",
        "- [ 3 - Evaluate Generated Summaries with ROUGE](#3)\n",
        "    - [ 3.1 - Understand ROUGE with an Example](#3.1)\n",
        "    - [ 3.2 - What are the Limitations?](#3.2)\n",
        "    - [ 3.3 - The Evaluate Library](#3.3)\n",
        "- [ 4 - Explore Dataset Loading with HuggingFace](#4)\n",
        "    - [ 4.1 - XSUM](#4.1)\n",
        "    - [ 4.2 - Exercises](#4.2)\n",
        "- [ 5 - News Summarization with BART](#5)\n",
        "    - [ 5.1 - Define Hyperparameters](#5.1)\n",
        "    - [ 5.2 - Zero-Shot Inference](#5.2)\n",
        "    - [ 5.3 - Few-Shot Learning](#5.3)\n",
        "- [ 6 - Legal Case Summarization](#6)\n",
        "    - [ 6.1 - BART](#6.1)\n",
        "    - [ 6.2 - LED](#6.2)\n",
        "    - [ 6.3 - Segmentation-based Pipeline](#6.3)\n",
        "- [ 7 - Summarize Dialogue with Prompt Engineering](#7)\n",
        "    - [ 7.1 Dataset and Model Loading](#7.1)\n",
        "    - [ 7.2 Summarize Dialogue without Prompt Engineering](#7.2)\n",
        "    - [ 7.3 Summarize Dialogue with an Instruction Prompt](#7.3)\n",
        "        - [ 7.3.1 Zero Shot Inference with an Instruction Prompt](#7.3.1)\n",
        "        - [ 7.3.2 Zero Shot Inference with the Prompt Template from FLAN-T5](#7.3.2)\n",
        "    - [ 7.4 Summarize Dialogue with One Shot and Few Shot Inference](#7.4)\n",
        "        - [ 7.4.1 One Shot Inference](#7.4.1)\n",
        "        - [ 7.4.2 Few Shot Inference](#7.4.2)\n",
        "- [ 8 - Dialogue Summarization with Parameter-Efficient Fine-tuning](#8)\n",
        "    - [ 8.1 - Preprocessing](#8.1)\n",
        "    - [ 8.2 - Fine-tuning](#8.2)\n",
        "    - [ 8.3 - Parameter-Efficient Fine-tuning (PEFT) with LoRA](#8.3)\n",
        "    - [ 8.4 - Fine-tuning Big LLMs with Unsloth](#8.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6dH24DBRoja"
      },
      "source": [
        "<a name='0'></a>\n",
        "## ‚öôÔ∏è 0 - Setup Kernel and Required Dependencies\n",
        "\n",
        "First, check that the Runtime type is `Python 3` with a `GPU`-based hardware accelerator.\n",
        "\n",
        "Go to \"Runtime\" $‚Üí$ \"Change runtime type\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6TDBnUxJzWU"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Brief Introduction on Automatic Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKd1MAcdKB5J"
      },
      "source": [
        "**Text Summarization** is the process of **shortening** a text document by automatically creating a compact, accurate, and fluent summary with the original **document's key points**\n",
        "\n",
        "There are two main kinds of summarization techniques based on output format: **Extractive** and **Abstractive**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8UvRTDBKSC6"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "### 1.1 - Extractive Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cICwqv9Kbux"
      },
      "source": [
        "\n",
        "![extractive.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "\n",
        "*   The most relevant **sentences are extracted and concatenated** to get the summary\n",
        "*   The summary is usually **not fluent**\n",
        "*   The extraction can be formulated as a **binary classification problem** (by predicting whether a sentence should be included in the summary) or extracting the **most scored sentences** based on syntactic and semantic relationships\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmXl3DdfKXQp"
      },
      "source": [
        "<a name='1.2'></a>\n",
        "### 1.2 - Abstractive Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFmZWeBgKuBj"
      },
      "source": [
        "![abstractive.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "*   Generation of **new sentences** providing the document's most relevant information\n",
        "\n",
        "*   **Human-like** process\n",
        "\n",
        "*   The summary is usually **fluent** but may contain **hallucinations**!\n",
        "\n",
        "*   **More challenging** task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ALRTBm2H0yd"
      },
      "source": [
        "<a name='2'></a>\n",
        "## üë®‚Äçüíª 2 - Understand How Language Models Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgFYocSsa2_t"
      },
      "source": [
        "Install dependencies...\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "RNs_bAEo0LAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e989b4f-a051-4531-ead1-4bc2d12ae47c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==2.14.6 in /usr/local/lib/python3.11/dist-packages (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.17.0)\n",
            "Requirement already satisfied: transformers==4.38.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]==4.38.1) (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.1->transformers[torch]==4.38.1) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from transformers[torch]==4.38.1) (2.5.1+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]==4.38.1) (0.27.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->transformers[torch]==4.38.1) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1->transformers[torch]==4.38.1) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1->transformers[torch]==4.38.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->transformers[torch]==4.38.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->transformers[torch]==4.38.1) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.1->transformers[torch]==4.38.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.1->transformers[torch]==4.38.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.1->transformers[torch]==4.38.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.1->transformers[torch]==4.38.1) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->transformers[torch]==4.38.1) (3.0.2)\n",
            "Requirement already satisfied: accelerate==0.27.2 in /usr/local/lib/python3.11/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2025.1.31)\n",
            "Requirement already satisfied: bitsandbytes==0.42.0 in /usr/local/lib/python3.11/dist-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.42.0) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->bitsandbytes==0.42.0) (1.26.4)\n",
            "Requirement already satisfied: evaluate==0.4.0 in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.0) (2023.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (24.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate==0.4.0) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate==0.4.0) (3.11.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate==0.4.0) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.0) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.0) (1.17.0)\n",
            "Requirement already satisfied: bert_score==0.3.12 in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (2.5.1+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (4.38.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score==0.3.12) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score==0.3.12) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score==0.3.12) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score==0.3.12) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score==0.3.12) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score==0.3.12) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score==0.3.12) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score==0.3.12) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score==0.3.12) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score==0.3.12) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score==0.3.12) (0.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score==0.3.12) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score==0.3.12) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score==0.3.12) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score==0.3.12) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score==0.3.12) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score==0.3.12) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score==0.3.12) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score==0.3.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score==0.3.12) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score==0.3.12) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score==0.3.12) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score==0.3.12) (3.0.2)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==2.14.6\n",
        "!pip install transformers[torch]==4.38.1\n",
        "!pip install accelerate==0.27.2\n",
        "!pip install bitsandbytes==0.42.0\n",
        "!pip install evaluate==0.4.0\n",
        "!pip install bert_score==0.3.12\n",
        "!pip install rouge_score\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCRrZJtbbD6z"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRqG_L0LQSWs"
      },
      "source": [
        "Set a seed for reproducibility: we want to allow everyone to reproduce the experiments with the same results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "Fof3mn2XQPbr"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLy0UiTSLvHY"
      },
      "source": [
        "<a name='2.1'></a>\n",
        "### 2.1 - Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FweFPlq6aCvf",
        "outputId": "eda1f123-7c05-4016-9b19-3783d52006c8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 47199 has 14.72 GiB memory in use. Of the allocated memory 14.37 GiB is allocated by PyTorch, and 220.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-cba907463890>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# We leverage the gradient checkpointing to save memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2554\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2555\u001b[0m                 )\n\u001b[0;32m-> 2556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 47199 has 14.72 GiB memory in use. Of the allocated memory 14.37 GiB is allocated by PyTorch, and 220.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "from accelerate import Accelerator\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "\n",
        "model_checkpoint = \"facebook/bart-large\"\n",
        "\n",
        "# We need it to leverage fp16 (mixed precision) computation to save memory and accelerate the training.\n",
        "accelerator = Accelerator(mixed_precision=\"fp16\", gradient_accumulation_steps=1)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(accelerator.device)\n",
        "\n",
        "# We leverage the gradient checkpointing to save memory.\n",
        "model.gradient_checkpointing_enable()\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy4bPaa-M-DB"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "### 2.2 - What's the input like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSGqmWbxH0Yt"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "colors_list = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "def show_tokens(sentence, tokenizer):\n",
        "    \"\"\"\n",
        "    Show highlighted tokens and input lengths.\n",
        "    \"\"\"\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "    for idx, t in enumerate(token_ids):\n",
        "        print(\n",
        "            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "            tokenizer.decode(t) +\n",
        "            '\\x1b[0m',\n",
        "            end=' '\n",
        "        )\n",
        "    print(\"\\n\")\n",
        "    print(token_ids)\n",
        "    print(f\"\\n\\nNumber of words: {len(nltk.word_tokenize(sentence))}\\nNumber of tokens: {len(token_ids)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrKIlmGYH0Bo"
      },
      "outputs": [],
      "source": [
        "input_text = \"How do large language models work?\"\n",
        "\n",
        "show_tokens(input_text, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2KbEjXJK3Y1"
      },
      "outputs": [],
      "source": [
        "input_text = \"Look at this tokenization segmentation\"\n",
        "\n",
        "show_tokens(input_text, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sux-r1aseJea"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "### 2.3 - What About the Output?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSNMTimxd2G8"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiWWCHcacsIw"
      },
      "outputs": [],
      "source": [
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4yx_3egb2U8"
      },
      "outputs": [],
      "source": [
        "# Prediction scores for each vocabulary token before SoftMax.\n",
        "logits = model(input_ids).logits\n",
        "print(logits)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE9F9DyieDuN"
      },
      "outputs": [],
      "source": [
        "output_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=50,\n",
        ")\n",
        "print(output_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBFGXYCSes_6"
      },
      "outputs": [],
      "source": [
        "output = tokenizer.batch_decode(output_ids, skip_special_tokens=False)[0]\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMs often struggle with basic arithmetic, but not for the reasons one might initially assume. The issue stems from how numbers are tokenized, which is optimized for language efficiency rather than mathematical operations.\n",
        "\n",
        "In most LLM tokenizers, including GPT-2's:\n",
        "1. Single-token number representation:\n",
        "   - The integers 0-9 don't each get their own unique token.\n",
        "   - Instead, many multi-digit numbers are assigned single tokens.\n",
        "\n",
        "2. Frequency-based tokenization - the image below shows the integers from 1 to 10k, with 100 per row. <mark>If a square is colored yellow it means a unique token is assigned to that integer and if it is purple then the integer is coded by a composite set of tokens</mark> in the GPT-2 tokenizer:\n",
        "   - The first 512 integers each get a unique token.\n",
        "   - Years between 1930 and 2019 also receive individual tokens.\n",
        "   - This is due to their frequent occurrence in training data.\n",
        "\n",
        "3. Inconsistent number representation:\n",
        "   - Some numbers are represented by single tokens.\n",
        "   - Others are broken into multiple tokens.\n",
        "   - This lack of consistency complicates arithmetic processing.\n",
        "\n",
        "4. Mathematical vs. linguistic optimization:\n",
        "   - The tokenization is optimized for language modeling efficiency.\n",
        "   - It's not designed with mathematical operations in mind.\n",
        "\n",
        "5. Computational challenge:\n",
        "   - Before performing calculations, the LLM must deconstruct these linguistically-optimized number representations.\n",
        "   - This extra step introduces complexity and potential for error.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://media.licdn.com/dms/image/v2/D4D22AQHSvid4S7Tznw/feedshare-shrink_800/feedshare-shrink_800/0/1727853729032?e=1730937600&v=beta&t=3uiOc9kLZ9O7vAOLJEvc4VMyloQMfjlveH4V2IyFj_Y\" alt=\"Tokenizing Digits\">\n",
        "\n",
        "<br><br>\n",
        "\n",
        "LLMs are terrible at spelling, too.\n",
        "\n",
        "<img src=\"https://global.discourse-cdn.com/openai1/optimized/4X/5/c/0/5c0d5882b9651fab40a71246423bdd0f9781b0e6_2_509x499.jpeg\" alt=\"Strawbarry problem\">\n",
        "\n",
        "<br><br>\n",
        "\n",
        "> What about different languages?!\n",
        "\n",
        "Have a look at [this Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:7247143812853059584/) for more references"
      ],
      "metadata": {
        "id": "y1XWu56czFD-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q-Ac6AHeJ3q"
      },
      "source": [
        "<a name='3'></a>\n",
        "## üë®‚Äçüíª 3 - Evaluate Generated Summaries with ROUGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enJlvCL9gL8_"
      },
      "source": [
        "**ROUGE** stands for Recall-Oriented Understudy for Gisting Evaluation.\n",
        "\n",
        "ROUGE is the leading evaluation metric for text summarization that compares a model-generated summary against the reference human-annotated one. It works by matching the **n-grams overlaps** of the generated and gold summary. Several metrics are available:\n",
        "\n",
        "* **ROUGE-1** refers to the **overlap of uni-grams** (each word) between the generated and reference summaries.\n",
        "\n",
        "* **ROUGE-2** refers to the **overlap of bi-grams**  (pairs of words) between the generated and reference summaries.\n",
        "\n",
        "* **ROUGE-L** identifies the longest n-grams co-occurring in the two sequences (**Longest Common Subsequence**).\n",
        "\n",
        "The scores range from 0 to 1 (we report the %, i.e., between 0 and 100; the higher, the better)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fhS39yhhB3q"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "### 3.1 - Understand ROUGE with an Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIQUyAdlftrZ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def get_rouge_scores(predictions, references):\n",
        "    \"\"\"\n",
        "    Compute and return the ROUGE metrics (R1, R2, RL, each with precision, recall, f1 scores).\n",
        "    \"\"\"\n",
        "    rouge_output = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
        "    return {\n",
        "        \"r1-p\": round(rouge_output[\"rouge1\"].mid.precision * 100, 2),\n",
        "        \"r1-r\": round(rouge_output[\"rouge1\"].mid.recall * 100, 2),\n",
        "        \"r1-f1\": round(rouge_output[\"rouge1\"].mid.fmeasure * 100, 2),\n",
        "        \"r2-p\": round(rouge_output[\"rouge2\"].mid.precision * 100, 2),\n",
        "        \"r2-r\": round(rouge_output[\"rouge2\"].mid.recall * 100, 2),\n",
        "        \"r2-f1\": round(rouge_output[\"rouge2\"].mid.fmeasure * 100, 2),\n",
        "        \"rL-p\": round(rouge_output[\"rougeL\"].mid.precision * 100, 2),\n",
        "        \"rL-r\": round(rouge_output[\"rougeL\"].mid.recall * 100, 2),\n",
        "        \"rL-f1\": round(rouge_output[\"rougeL\"].mid.fmeasure * 100, 2)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjxXmPr0fuE1"
      },
      "outputs": [],
      "source": [
        "predictions = [\"I absolutely loved reading the Hunger Games\"]\n",
        "references = [\"i loved reading the Hunger Games.\"]\n",
        "\n",
        "scores = get_rouge_scores(predictions=predictions, references=references)\n",
        "\n",
        "print(f'rouge-1:\\t P:{scores[\"r1-p\"]} \\t R:{scores[\"r1-r\"]} \\t F1:{scores[\"r1-f1\"]}')\n",
        "print(f'rouge-2:\\t P:{scores[\"r2-p\"]} \\t R:{scores[\"r2-r\"]} \\t F1:{scores[\"r2-f1\"]}')\n",
        "print(f'rouge-L:\\t P:{scores[\"rL-p\"]} \\t R:{scores[\"rL-r\"]} \\t F1:{scores[\"rL-f1\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWlF_otvhMFw"
      },
      "source": [
        "**Note**: ROUGE is case-insensitive (\"I\" and \"i\" are the same) and does not consider punctuactions (\".\" in the reference)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXUzMJnwhM53"
      },
      "source": [
        "For ROUGE, \"recall\" (R) measures how much of the reference summary is captured by the generated one (i.e., *how many words of the reference are within the prediction?*). If we are just comparing words, \"recall\" can be calculated according to the following formula:\n",
        "\n",
        "$$Recall = \\frac{\\text{Number of overlapping words}}{\\text{Total number of words in reference summary}}$$\n",
        "\n",
        "For our simple example above, this formula gives a perfect recall of 6/6 = 1; i.e., *all the words in the reference summary have been produced by the model*.\n",
        "\n",
        "This may sound great, but imagine if our generated summary had been \"I really really loved reading the Hunger Games all night.\" This would also have perfect recall, but is arguably a worse summary since it is verbose. To deal with these scenarios, we also compute the \"precision\", which in the ROUGE context measures how much of the generated summary was relevant (i.e., *how many words of the prediction are within the reference?*):\n",
        "\n",
        "$$Precision = \\frac{\\text{Number of overlapping words}}{\\text{Total number of words in generated summary}}$$\n",
        "\n",
        "Applying this to our verbose summary gives a \"precision\" of 6/10 = 0.6, which is considerably worse than the \"precision\" of 6/7 = 0.86 obtained by our shorter one (in the cell above). In practice, both \"precision\" and \"recall\" are usually computed, and then the \"F1-score\" (i.e., the harmonic mean of \"precision\" and \"recall\") is reported:\n",
        "\n",
        "$$F_1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh36BQylh2tX"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "### 3.2 - What are the Limitations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FByhjGriKTT"
      },
      "source": [
        "1. The sentences are semantically the same (i.e., they have the same meaning), but ROUGE evaluates only the syntactic aspect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwxUjpCZiK0j"
      },
      "outputs": [],
      "source": [
        "references = [\"a big man is sad\"]\n",
        "predictions = [\"the huge guy was not happy\"]\n",
        "\n",
        "scores = get_rouge_scores(predictions=predictions, references=references)\n",
        "\n",
        "print(f'rouge-1:\\t P:{scores[\"r1-p\"]} \\t R:{scores[\"r1-r\"]} \\t F1:{scores[\"r1-f1\"]}')\n",
        "print(f'rouge-2:\\t P:{scores[\"r2-p\"]} \\t R:{scores[\"r2-r\"]} \\t F1:{scores[\"r2-f1\"]}')\n",
        "print(f'rouge-L:\\t P:{scores[\"rL-p\"]} \\t R:{scores[\"rL-r\"]} \\t F1:{scores[\"rL-f1\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivg-fdhoiUBb"
      },
      "source": [
        "2. The sentences have the same words, but ROUGE-2 and ROUGE-L consider the word position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32m71Lc4iTX1"
      },
      "outputs": [],
      "source": [
        "references = [\"a big man is sad\"]\n",
        "predictions = [\"is sad a big man\"]\n",
        "\n",
        "scores = get_rouge_scores(predictions=predictions, references=references)\n",
        "\n",
        "print(f'rouge-1:\\t P:{scores[\"r1-p\"]} \\t R:{scores[\"r1-r\"]} \\t F1:{scores[\"r1-f1\"]}')\n",
        "print(f'rouge-2:\\t P:{scores[\"r2-p\"]} \\t R:{scores[\"r2-r\"]} \\t F1:{scores[\"r2-f1\"]}')\n",
        "print(f'rouge-L:\\t P:{scores[\"rL-p\"]} \\t R:{scores[\"rL-r\"]} \\t F1:{scores[\"rL-f1\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CxVive0iaoU"
      },
      "source": [
        "3. The sentences have opposite meaning, but ROUGE does not fully capture this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAJbGadqiaPD"
      },
      "outputs": [],
      "source": [
        "references = [\"a big man born in New York is sad\"]\n",
        "predictions = [\"a big man born in New York is not sad\"]\n",
        "\n",
        "scores = get_rouge_scores(predictions=predictions, references=references)\n",
        "\n",
        "print(f'rouge-1:\\t P:{scores[\"r1-p\"]} \\t R:{scores[\"r1-r\"]} \\t F1:{scores[\"r1-f1\"]}')\n",
        "print(f'rouge-2:\\t P:{scores[\"r2-p\"]} \\t R:{scores[\"r2-r\"]} \\t F1:{scores[\"r2-f1\"]}')\n",
        "print(f'rouge-L:\\t P:{scores[\"rL-p\"]} \\t R:{scores[\"rL-r\"]} \\t F1:{scores[\"rL-f1\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaSr6RnkkdSk"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "### 3.3 - The Evaluate Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfWttG62koDz"
      },
      "source": [
        "We report the correct approach to compute the ROUGE scores (despite it does not provide precision and recall scores).\n",
        "\n",
        "The output is the following dictionary:\n",
        "\n",
        "{'rouge1',\n",
        " 'rouge2',\n",
        " 'rougeL',\n",
        " 'rougeLsum'\n",
        "}\n",
        "\n",
        "The \"sum\" in \"rougeLsum\" refers to the fact that this metric is computed over a whole summary, while \"rougeL\" is computed as the average over individual sentences.\n",
        "\n",
        "**Note:** since in our examples there is only one sentence for both the reference and prediction, \"rougeL\" and \"rougeLsum\" will be the same."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "4aIqLANu25oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpZvpKq9knvn"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import nltk\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHQz2ff-kcwi"
      },
      "outputs": [],
      "source": [
        "def postprocess_text(predictions, references):\n",
        "    \"\"\"\n",
        "    Preprocess the text before computing ROUGE.\n",
        "    \"\"\"\n",
        "    preds = [pred.strip() for pred in predictions]\n",
        "    labels = [label.strip() for label in references]\n",
        "    # rougeLsum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def get_rouge_scores(predictions, references):\n",
        "    \"\"\"\n",
        "    Compute and return the ROUGE scores.\n",
        "    \"\"\"\n",
        "    predictions, references = postprocess_text(predictions, references)\n",
        "    result_rouge = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
        "    result = {k: round(v * 100, 2) for k, v in result_rouge.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3jq3pHYlhdw"
      },
      "outputs": [],
      "source": [
        "references = [\"a big man born in New York is sad\"]\n",
        "predictions = [\"a big man born in New York is not sad\"]\n",
        "\n",
        "scores = get_rouge_scores(predictions, references)\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvwRvUuWnDpi"
      },
      "source": [
        "<a name='4'></a>\n",
        "## üë®‚Äçüíª 4 - Explore Dataset Loading with HuggingFace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quqmPDENorhj"
      },
      "source": [
        "<a name='4.1'></a>\n",
        "### 4.1 - XSUM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqksQavXnDYb"
      },
      "source": [
        "We explore [XSum](https://huggingface.co/datasets/EdinburghNLP/xsum), one of the most known datasets for Text Summarization. It contains over 200K BBC articles with the corresponding manually labeled one-sentence summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfWcvYLnhzfn"
      },
      "source": [
        "Download the dataset...\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j6B0Lp2nZdT"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "xsum = load_dataset(\"EdinburghNLP/xsum\")\n",
        "\n",
        "print(xsum)\n",
        "\n",
        "xsum_train = xsum[\"train\"] # need it to train models how to summarize the documents\n",
        "xsum_eval = xsum[\"validation\"] # need it to track model performance during training to avoid overfitting\n",
        "xsum_test = xsum[\"test\"] # need it to evaluate model performance once the model is already trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2OVgnpah5Qh"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34n6vEojn6uU"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "def show_random_samples(dataset, num_examples=3):\n",
        "    \"\"\"\n",
        "    Show random samples from a dataset.\n",
        "    \"\"\"\n",
        "    assert num_examples <= len(dataset), \"Can't pick more samples than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset) - 1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset) - 1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSq0WCG9n-rQ"
      },
      "outputs": [],
      "source": [
        "show_random_samples(xsum_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdTwucYWo9M0"
      },
      "source": [
        "<a name='4.2'></a>\n",
        "### 4.2 - Exercises ‚úèÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5sX-SN3pJCC"
      },
      "source": [
        "Try it out!\n",
        "\n",
        "1. Calculate the average number of words (using \"nltk.word_tokenize\") and tokens (using BART's tokenizer) in the documents and summaries of XSUM. **Note:** we want these statistics on the entire dataset (without considering the splits).\n",
        "2. Re-calculate these statistics per split to verify if the splits are balanced in document statistics.\n",
        "3. Which is the average document compression? (*Compression is the ratio between the number of source words and the number of target words*)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO"
      ],
      "metadata": {
        "id": "N9P9uFDAgF9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEKikfMdEAPa"
      },
      "source": [
        "<a name='5'></a>\n",
        "## üë®‚Äçüíª 5 - News Summarization with BART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0ba-mg8VYp7"
      },
      "source": [
        "In this part of the notebook, you will fine-tune a generative language model from HuggingFace for news document summarization.\n",
        "You will use the [BART](https://huggingface.co/docs/transformers/model_doc/bart) model, which is an encoder-decoder transformer trained using masked language modeling (MLM) as unsupervised training objective, where tokens are masked and the model has learned to predict them (**denoising objective**).\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*xYqyt4Gzl1SAioip9NdaXQ.png)\n",
        "\n",
        "To improve the inferences, you will explore a fine-tuning approach and evaluate the results with ROUGE metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKB1spO6EPJx"
      },
      "source": [
        "<a name='5.1'></a>\n",
        "### 5.1 - Define Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG8sId_2XG-F"
      },
      "source": [
        "It is possible to pull out the number of model parameters and find out how many of them are trainable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUA8QPrMXHYC"
      },
      "outputs": [],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXJ5I_JbE0Qt"
      },
      "outputs": [],
      "source": [
        "# The max input size that BART can process (it is limited to max 1024 tokens).\n",
        "max_source_length = 1024\n",
        "\n",
        "# The max output size that BART must generate (it depends on the average\n",
        "# summary size of the dataset under cosideration).\n",
        "min_target_length = 10\n",
        "max_target_length = 64\n",
        "\n",
        "# The penalty ensures that no n-gram (3-grams here) appears twice by manually setting\n",
        "# the probability of the following words that could create an already seen n-gram to 0.\n",
        "no_repeat_ngram_size = 3\n",
        "\n",
        "# The number of instances processed by models at each step.\n",
        "# Note: the larger the batch size, the larger the GPU memory required.\n",
        "batch_size = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6NHTvFZFrVq"
      },
      "source": [
        "<a name='5.2'></a>\n",
        "### 5.2 - Zero-Shot Inference\n",
        "Zero-shot inference (in this context) refers to prompting the model with the input instances without any fine-tuning to align the model with the target task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTvctl8wFMov"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def test(model, tokenizer, dataset, accelerator, text_column, summary_column, max_source_length, min_target_length,\n",
        "         max_target_length, stop_ngrams, epoch, is_eval, has_glob_attn=False, is_primera=False):\n",
        "    \"\"\"\n",
        "    Generate summaries from a list of documents.\n",
        "    \"\"\"\n",
        "    if is_eval and epoch is not None:\n",
        "        print(\"***** Running validation *****\")\n",
        "        print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n",
        "    else:\n",
        "        print(f\"***** Running test *****\")\n",
        "    print(f\"Num examples = {len(dataset)}\")\n",
        "\n",
        "    # We need it to create the batches from data.\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    if is_eval:\n",
        "        dataloader = accelerator.prepare(dataloader)  # It is required for using the training acceleration.\n",
        "\n",
        "    progress_bar = tqdm(range(len(dataloader)))  # A handy progress bar.\n",
        "\n",
        "    predictions = []\n",
        "    model.eval()  # We set the model in the evaluation status (no dropout layers are applied).\n",
        "\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        with torch.no_grad():  # Of course, no training happens here.\n",
        "\n",
        "            document = batch[text_column]  # Get the document (with batch_size=2, we have a list of 2 documents).\n",
        "\n",
        "            # Tokenize the input (will be a pytorch tensor).\n",
        "            # Truncate the inputs longer than max_length (1024 here).\n",
        "            # Pad shorter sequences to 1024 tokens if shorter.\n",
        "            input_dict = tokenizer(document, return_tensors=\"pt\", truncation=True,\n",
        "                                   padding=True, max_length=max_source_length)\n",
        "\n",
        "            # Input ids: the sequence of tokens.\n",
        "            input_ids = input_dict[\"input_ids\"].to(model.device)\n",
        "\n",
        "            # Attention mask: let models understand which are the token to process or to ignore (pad tokens).\n",
        "            # In practice: it put a 0 if the token is a pad token, 0 otherwise.\n",
        "            attention_mask = input_dict[\"attention_mask\"].to(model.device)\n",
        "\n",
        "            if is_eval:\n",
        "                model = accelerator.unwrap_model(model)\n",
        "\n",
        "\n",
        "            # Only for models with linear attention (e.g., LED and PRIMERA).\n",
        "            if has_glob_attn:\n",
        "                # Global tokens attend to all other tokens (quadratic self-attention).\n",
        "                # For text summarization, only the first token (<s>) ha s gloabl attention.\n",
        "                global_attention_mask = torch.zeros_like(attention_mask)\n",
        "                global_attention_mask[:, 0] = 1\n",
        "                # Only for PRIMERA.\n",
        "                if is_primera:\n",
        "                    global_attention_mask[input_ids == tokenizer.convert_tokens_to_ids(\"<doc-sep>\")] = 1\n",
        "\n",
        "                output_model = model.generate(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    global_attention_mask=global_attention_mask,\n",
        "                    max_length=max_target_length,\n",
        "                    min_length=min_target_length,\n",
        "                    early_stopping=True,\n",
        "                    num_beams=2,\n",
        "                    length_penalty=1.0,\n",
        "                    repetition_penalty=1.0,\n",
        "                    no_repeat_ngram_size=stop_ngrams,\n",
        "                )\n",
        "            else:\n",
        "                output_model = model.generate(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_length=max_target_length,\n",
        "                    min_length=min_target_length,\n",
        "                    early_stopping=True,\n",
        "                    num_beams=2,\n",
        "                    length_penalty=1.0,\n",
        "                    repetition_penalty=1.0,\n",
        "                    no_repeat_ngram_size=stop_ngrams,\n",
        "                )\n",
        "\n",
        "            # Decode the output tokens to obtain the textual summary.\n",
        "            prediction = tokenizer.batch_decode(output_model, skip_special_tokens=True)\n",
        "            predictions.extend(prediction)\n",
        "\n",
        "            progress_bar.update(1)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlEr9YZtlz4b"
      },
      "source": [
        "Based on the dataset, we take the name of the input and target columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHHku9BGlyzf"
      },
      "outputs": [],
      "source": [
        "text_column = \"document\"\n",
        "summary_column = \"summary\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ8AAlQVl6ww"
      },
      "source": [
        "To save time, we use just the first 10 samples of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoWQU0Bdl4h6"
      },
      "outputs": [],
      "source": [
        "max_test_samples = 10\n",
        "\n",
        "test_dataset = xsum_test.select(range(min(len(xsum_test), max_test_samples)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "1dUay55841Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XNXEn92F0aN"
      },
      "outputs": [],
      "source": [
        "predictions_zeroshot = test(\n",
        "    model, tokenizer, test_dataset, accelerator, text_column, summary_column, max_source_length,\n",
        "    min_target_length, max_target_length, no_repeat_ngram_size, epoch=None, is_eval=False\n",
        ")\n",
        "\n",
        "rouge_scores = get_rouge_scores(predictions=predictions_zeroshot, references=test_dataset[summary_column])\n",
        "\n",
        "print(f\"\\n\\nROUGE-1: {rouge_scores['rouge1']}\\nROUGE-2: {rouge_scores['rouge2']}\\nROUGE-L: {rouge_scores['rougeL']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUtBE3HPGhJU"
      },
      "source": [
        "Let's print a predicted summary along its human-annotated one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BggzE7qRGgwW"
      },
      "outputs": [],
      "source": [
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'HUMAN SUMMARY:\\n{xsum_test[summary_column][0]}')\n",
        "print(dash_line)\n",
        "print(f'MODEL SUMMARY:\\n{predictions_zeroshot[0]}')\n",
        "print(dash_line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGFV8x_lHVa8"
      },
      "source": [
        "<a name='5.3'></a>\n",
        "### 5.3 - Few-Shot Learning\n",
        "We will test now the effect that a few training steps have on the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yStHI7ELHgGN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from transformers import get_scheduler\n",
        "\n",
        "\n",
        "def train(model, tokenizer, train_dataset, eval_dataset, accelerator, text_column, summary_column, max_source_length,\n",
        "          min_target_length, max_target_length, stop_ngrams, has_glob_attn=False, is_primera=False):\n",
        "    \"\"\"\n",
        "    Train the model on text summarization.\n",
        "    \"\"\"\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    gradient_accumulation_steps = 1\n",
        "    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "    max_train_steps = num_epochs * num_update_steps_per_epoch\n",
        "\n",
        "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=5e-5)\n",
        "\n",
        "    num_warmup_steps = math.ceil(max_train_steps / 10) * gradient_accumulation_steps\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps * gradient_accumulation_steps,\n",
        "        num_training_steps=max_train_steps * gradient_accumulation_steps,\n",
        "    )\n",
        "\n",
        "    model, optimizer, lr_scheduler, train_dataloader = accelerator.prepare(\n",
        "        model, optimizer, lr_scheduler, train_dataloader\n",
        "    )\n",
        "\n",
        "    # We need to recalculate our total training steps as the size of the training dataloader may have changed.\n",
        "    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "    max_train_steps = num_epochs * num_update_steps_per_epoch\n",
        "    num_train_epochs = math.ceil(max_train_steps / num_update_steps_per_epoch)\n",
        "\n",
        "    total_batch_size = batch_size * gradient_accumulation_steps\n",
        "\n",
        "    progress_bar = tqdm(range(max_train_steps))\n",
        "    best_rouge_scores = 0\n",
        "\n",
        "    print(\"\\n***** Running training *****\")\n",
        "    print(f\"Num examples = {len(train_dataset)}\")\n",
        "    print(f\"Num epochs = {num_epochs}\")\n",
        "    print(f\"Total train batch size = {total_batch_size}\")\n",
        "    print(f\"Gradient accumulation steps = {gradient_accumulation_steps}\")\n",
        "    print(f\"Total optimization steps = {max_train_steps}\\n\")\n",
        "\n",
        "    for epoch in range(num_train_epochs):\n",
        "        model.train()  # Set the model in the training status (activate dropout layers).\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            document = batch[text_column]\n",
        "            summary = batch[summary_column]\n",
        "\n",
        "            input_dict = tokenizer(document, return_tensors=\"pt\", truncation=True, padding=True,\n",
        "                                       max_length=max_source_length)\n",
        "            input_ids = input_dict[\"input_ids\"].to(model.device)\n",
        "            attention_mask = input_dict[\"attention_mask\"].to(model.device)\n",
        "\n",
        "            output_dict = tokenizer(summary, return_tensors=\"pt\", truncation=True, padding=True,\n",
        "                                    max_length=max_target_length)\n",
        "\n",
        "            labels = output_dict[\"input_ids\"].to(model.device)\n",
        "            # Set the pad token to -100 (required to compute the loss).\n",
        "            labels = labels.where(labels != tokenizer.pad_token_id,\n",
        "                                  torch.tensor(-100, device=model.device))\n",
        "            decoder_attention_mask = output_dict[\"attention_mask\"].to(model.device)\n",
        "\n",
        "            global_attention_mask = None\n",
        "\n",
        "            # Only for LED and PRIMERA models.\n",
        "            if has_glob_attn:\n",
        "                global_attention_mask = torch.zeros_like(attention_mask)\n",
        "                global_attention_mask[:, 0] = 1\n",
        "                # Only for PRIMERA.\n",
        "                if is_primera:\n",
        "                    global_attention_mask[input_ids == tokenizer.convert_tokens_to_ids(\"<doc-sep>\")] = 1\n",
        "\n",
        "            with accelerator.accumulate(model):\n",
        "                if global_attention_mask is None:\n",
        "                    outputs = model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        labels=labels,\n",
        "                        decoder_attention_mask=decoder_attention_mask\n",
        "                    )\n",
        "                else:\n",
        "                    outputs = model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        global_attention_mask=global_attention_mask,\n",
        "                        labels=labels,\n",
        "                        decoder_attention_mask=decoder_attention_mask\n",
        "                    )\n",
        "                loss = outputs.loss  # Get the loss (is a tensor).\n",
        "\n",
        "                accelerator.backward(loss)  # Backpropagation.\n",
        "                optimizer.step()  # Update the optimizer.\n",
        "                lr_scheduler.step()  # Update the scheduler of the learning rate.\n",
        "                optimizer.zero_grad()  # Clear the gradients.\n",
        "\n",
        "            if accelerator.sync_gradients:\n",
        "                # Print the loss in the progress bar.\n",
        "                progress_bar.set_postfix_str(f\"Loss: {str(loss.item())}\")\n",
        "                progress_bar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Validation phase!\n",
        " 1. Test the model performance on the validation set.\n",
        " 2. Compute ROUGE scores and get the average score ([R1 + R2 + RL] / 3).\n",
        " 3. If the average score is greater than the score of the previous epoch, then save the model."
      ],
      "metadata": {
        "id": "T66mNtQajqPQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68qknO0RHwBi"
      },
      "source": [
        "To save time, as we did for the test set, we select only the first 100 and 10 instances for the training and validation sets, respectively.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTLLaetBHul4"
      },
      "outputs": [],
      "source": [
        "max_train_samples = 100  # It is a real-world low-resource scenario.\n",
        "train_dataset = xsum_train.select(range(min(len(xsum_train), max_train_samples)))\n",
        "\n",
        "# The number of times that the model processes the training data.\n",
        "num_epochs = 5\n",
        "\n",
        "max_eval_samples = 10\n",
        "eval_dataset = xsum_eval.select(range(min(len(xsum_eval), max_eval_samples)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1QsQ_NrT0gc"
      },
      "source": [
        "Start training process...\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPdj0p-HH76w"
      },
      "outputs": [],
      "source": [
        "train(\n",
        "    model, tokenizer, train_dataset, eval_dataset, accelerator, text_column, summary_column,\n",
        "    max_source_length, min_target_length, max_target_length, no_repeat_ngram_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpp5JOKCUWdp"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HY_JAL_H-4E"
      },
      "source": [
        "Let's generate the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zCepuWAIAvU"
      },
      "outputs": [],
      "source": [
        "predictions_fewshot = test(\n",
        "    model, tokenizer, test_dataset, accelerator, text_column, summary_column, max_source_length,\n",
        "    min_target_length, max_target_length, no_repeat_ngram_size, epoch=None, is_eval=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT99p5S9IFKk"
      },
      "source": [
        "Let's calculate the summaries' quality with ROUGE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gahr8dnhICyy"
      },
      "outputs": [],
      "source": [
        "rouge_scores = get_rouge_scores(predictions=predictions_fewshot, references=test_dataset[summary_column])\n",
        "\n",
        "print(rouge_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99Xgh2qXmn67"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'HUMAN SUMMARY:\\n{xsum_test[summary_column][idx]}')\n",
        "print(dash_line)\n",
        "print(f'0-SHOT MODEL SUMMARY:\\n{predictions_zeroshot[idx]}')\n",
        "print(dash_line)\n",
        "print(f'FEW-SHOT MODEL SUMMARY:\\n{predictions_fewshot[idx]}')\n",
        "print(dash_line)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> What do you notice? Do the summaries have the right content or the right style?"
      ],
      "metadata": {
        "id": "iTkO9CBlIjMK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQluupBqLKYi"
      },
      "source": [
        "<a name='5.4'></a>\n",
        "### 5.4 - Full Fine-Tuning\n",
        "What if we train on the whole dataset? To save time let's download a model from HuggingFace already trained on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcV-9yxrLRLx"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "\n",
        "model_checkpoint = \"facebook/bart-large-xsum\"\n",
        "\n",
        "# We need it to leverage fp16 (mixed precision) computation to save memory and accelerate the training.\n",
        "accelerator = Accelerator(mixed_precision=\"fp16\", gradient_accumulation_steps=1)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(accelerator.device)\n",
        "\n",
        "# We leverage the gradient checkpointing to save memory.\n",
        "model.gradient_checkpointing_enable()\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57z--xq2M6b6"
      },
      "outputs": [],
      "source": [
        "predictions_finetuned = test(\n",
        "    model, tokenizer, test_dataset, accelerator, text_column, summary_column, max_source_length,\n",
        "    min_target_length, max_target_length, no_repeat_ngram_size, epoch=None, is_eval=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfZSUVPCM-PP"
      },
      "outputs": [],
      "source": [
        "rouge_scores = get_rouge_scores(predictions=predictions_finetuned, references=test_dataset[summary_column])\n",
        "\n",
        "print(rouge_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K82YEQ18NA86"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'HUMAN SUMMARY:\\n{xsum_test[summary_column][idx]}')\n",
        "print(dash_line)\n",
        "print(f'0-SHOT MODEL SUMMARY:\\n{predictions_zeroshot[idx]}')\n",
        "print(dash_line)\n",
        "print(f'FEW-SHOT MODEL SUMMARY:\\n{predictions_fewshot[idx]}')\n",
        "print(dash_line)\n",
        "print(f'FINETUNED MODEL SUMMARY:\\n{predictions_finetuned[idx]}')\n",
        "print(dash_line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwrjwjioapug"
      },
      "source": [
        "<a name='6'></a>\n",
        "## üë®‚Äçüíª 6 - Legal Case Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klKOV-irbje7"
      },
      "source": [
        "In this second case study, we will explore the long document summarization task, showing the limitations that quadratic models (such as BART) have. The input is a long legal document with its corresponding summary.\n",
        "\n",
        "> Linear, Quadratic .. what‚Äôs the deal with these? Hang on, we will see them at the right moment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC7DBEULaupo"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "govreport = load_dataset(\"ccdv/govreport-summarization\")\n",
        "\n",
        "print(govreport)\n",
        "\n",
        "govreport_train = govreport[\"train\"]\n",
        "govreport_eval = govreport[\"validation\"]\n",
        "govreport_test = govreport[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGOkZfiWbyGj"
      },
      "outputs": [],
      "source": [
        "show_random_samples(govreport_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwkmaegSb7np"
      },
      "outputs": [],
      "source": [
        "text_column = \"report\"\n",
        "summary_column = \"summary\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ3LRKlNb9W-"
      },
      "outputs": [],
      "source": [
        "max_test_samples = 10\n",
        "\n",
        "test_dataset = govreport_test.select(range(min(len(govreport_test), max_test_samples)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTi9B8lichOI"
      },
      "outputs": [],
      "source": [
        "num_words_source = [len(nltk.word_tokenize(x)) for x in test_dataset[text_column]]\n",
        "num_words_target = [len(nltk.word_tokenize(x)) for x in test_dataset[summary_column]]\n",
        "\n",
        "print(f\"Num of words in the source -> MIN:{min(num_words_source)}\\tAVG: {sum(num_words_source)/len(num_words_source)}\\tMAX: {max(num_words_source)}\")\n",
        "print(f\"Num of words in the target -> MIN:{min(num_words_target)}\\tAVG: {sum(num_words_target)/len(num_words_target)}\\tMAX: {max(num_words_target)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-bTbiZudibE"
      },
      "source": [
        "<a name='6.1'></a>\n",
        "### üë®‚Äçüíª 6.1 - BART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsy_4XlXe1BE"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "\n",
        "model_checkpoint = \"twigs/facebook-bart-large-1024-govreport\"\n",
        "\n",
        "# We need it to leverage fp16 (mixed precision) computation to save memory and accelerate the training.\n",
        "accelerator = Accelerator(mixed_precision=\"fp16\", gradient_accumulation_steps=1)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(accelerator.device)\n",
        "\n",
        "# We leverage the gradient checkpointing to save memory.\n",
        "model.gradient_checkpointing_enable()\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr5vSyIWl_Yj"
      },
      "outputs": [],
      "source": [
        "max_source_length = 1024\n",
        "min_target_length = 10\n",
        "max_target_length = 256\n",
        "\n",
        "no_repeat_ngram_size = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGFFuFRmfH3"
      },
      "source": [
        "Start inference...\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izzeYGQgfURv"
      },
      "outputs": [],
      "source": [
        "predictions_bart = test(\n",
        "    model, tokenizer, test_dataset, accelerator, text_column, summary_column, max_source_length,\n",
        "    min_target_length, max_target_length, no_repeat_ngram_size, epoch=None, is_eval=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGSCMSngfcoy"
      },
      "outputs": [],
      "source": [
        "rouge_scores_bart = get_rouge_scores(predictions=predictions_bart, references=test_dataset[summary_column])\n",
        "\n",
        "print(rouge_scores_bart)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsgNvrfDdnZT"
      },
      "source": [
        "<a name='6.2'></a>\n",
        "### üë®‚Äçüíª 6.2 - LED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwzUIflBfjSZ"
      },
      "source": [
        "**LED** (Longformer-Encoder-Decoder) is an encoder-decoder transformer that differs from BART because of its attention mechanism, which scales linearly in the input size. Thus, this model belongs to the family of linear (efficient) transformers.\n",
        "For the sake of time, we load an already full finetuned LED model on GovReport."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4UfQMa8frT5"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"Xmm/led-large-16384-govreport\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint).to(accelerator.device)\n",
        "model.gradient_checkpointing_enable()\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q98F5qQGhzZ4"
      },
      "outputs": [],
      "source": [
        "# Actually, LED can process up to 16384 tokens, but for memory limitations, we set 4096 tokens as the max input size.\n",
        "max_source_length = 4096\n",
        "min_target_length = 10\n",
        "max_target_length = 512\n",
        "\n",
        "no_repeat_ngram_size = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP757ubch40a"
      },
      "outputs": [],
      "source": [
        "predictions_led = test(\n",
        "    model, tokenizer, test_dataset, accelerator, text_column, summary_column, max_source_length,\n",
        "    min_target_length, max_target_length, no_repeat_ngram_size, epoch=None, is_eval=False, has_glob_attn=True\n",
        ")\n",
        "\n",
        "rouge_scores_led = get_rouge_scores(predictions=predictions_led, references=test_dataset[summary_column])\n",
        "\n",
        "print(rouge_scores_led)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRbo1iT8wlwF"
      },
      "source": [
        "<a name='7'></a>\n",
        "## üë®‚Äçüíª 7 - Summarize Dialogue with Prompt Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg-8K9cVwlwF"
      },
      "source": [
        "In this part of the lab you will do the dialogue summarization task using generative AI. You will explore **how the input text affects the output of the model**, and perform **prompt engineering** to direct it towards the task you need. By comparing zero shot, one shot, and few shot inferences, you will take the first step towards prompt engineering and see how it can enhance the generative output of Large Language Models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFXNgvUwwlwF"
      },
      "source": [
        "Now install the required packages to use PyTorch and Hugging Face transformers and datasets.\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5JZ25vcmUgdGhlIHdhcm5pbmdzIGFuZCBlcnJvcnMsIGFsb25nIHdpdGggdGhlIG5vdGUgYWJvdXQgcmVzdGFydGluZyB0aGUga2VybmVsIGF0IHRoZSBlbmQuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nax_GPhbwlwF"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install --disable-pip-version-check \\\n",
        "    torch==1.13.1 \\\n",
        "    torchdata==0.5.1 --quiet\n",
        "\n",
        "%pip install \\\n",
        "    transformers==4.27.2 \\\n",
        "    datasets==2.11.0  --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H4qFx-rwlwF"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URJv6yCvwlwF"
      },
      "source": [
        "Load the datasets, Large Language Model (LLM), tokenizer, and configurator. Do not worry if you do not understand yet all of those components - they will be described and discussed later in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qaw-U0fSwlwF"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GenerationConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awLWIpg-wlwF"
      },
      "source": [
        "<a name='7.1'></a>\n",
        "### 7.1 - Dataset and Model Loading\n",
        "\n",
        "In this use case, you will be generating a summary of a dialogue with the pre-trained Large Language Model (LLM) FLAN-T5 from Hugging Face. The list of available models in the Hugging Face `transformers` package can be found [here](https://huggingface.co/docs/transformers/index).\n",
        "\n",
        "Let's upload some simple dialogues from the [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) Hugging Face dataset. This dataset contains 10,000+ dialogues with the corresponding manually labeled summaries and topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9VtUNaYwlwG"
      },
      "outputs": [],
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcYn_J1RwlwH"
      },
      "source": [
        "Print a couple of dialogues with their baseline summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXxy8G0qwlwH"
      },
      "outputs": [],
      "source": [
        "example_indices = [40, 200]\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print('INPUT DIALOGUE:')\n",
        "    print(dataset['test'][index]['dialogue'])\n",
        "    print(dash_line)\n",
        "    print('BASELINE HUMAN SUMMARY:')\n",
        "    print(dataset['test'][index]['summary'])\n",
        "    print(dash_line)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnbmqrs4wlwH"
      },
      "source": [
        "For the experiments in the following sections we will use the `Flan-T5-base` model. The [T5 (Text-To-Text Transfer Transformer)](https://arxiv.org/abs/1910.10683) model was finetuned by pre-pending short, task-specific instructions to the input data instances. **This allowed the model to treat a wide variety of NLP tasks uniformly, simply by formatting each task as a text transformation problem**. For example, a summarization task could be framed as: _\"summarize: [input text]\"_, while a translation task might start with _\"translate English to French: [input text]\"_.\n",
        "\n",
        "**By adding these task prompts, T5 learned to generalize across different NLP tasks with minimal structural changes**, making the model both flexible and efficient in adapting to new tasks through transfer learning.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CgIp9Y5-6lLdKDrocKQaCQ.png\" alt=\"T5 Fine-Tuning\" width=\"800\"/>\n",
        "</p>\n",
        "\n",
        "\n",
        "You need to convert the dialog-summary (prompt-response) pairs into explicit instructions for the LLM. Prepend an instruction to the start of the dialog with `Summarize the following conversation` and to the start of the summary with `Summary` as follows:\n",
        "\n",
        "Training prompt (dialogue):\n",
        "```\n",
        "Summarize the following conversation.\n",
        "\n",
        "    Chris: This is his part of the conversation.\n",
        "    Antje: This is her part of the conversation.\n",
        "    \n",
        "Summary:\n",
        "```\n",
        "\n",
        "Training response (summary):\n",
        "```\n",
        "Both Chris and Antje participated in the conversation.\n",
        "```\n",
        "\n",
        "Then preprocess the prompt-response dataset into tokens and pull out their `input_ids` (1 per token).\n",
        "\n",
        "\n",
        "\n",
        "Load the [FLAN-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5), creating an instance of the `AutoModelForSeq2SeqLM` class with the `.from_pretrained()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IFBKYnEwlwH"
      },
      "outputs": [],
      "source": [
        "model_name='google/flan-t5-base'\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8SvyFZqwlwH"
      },
      "source": [
        "Download the tokenizer for the FLAN-T5 model using `AutoTokenizer.from_pretrained()` method. Parameter `use_fast` switches on fast tokenizer. At this stage, there is no need to go into the details of that, but you can find the tokenizer parameters in the [documentation](https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/auto#transformers.AutoTokenizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxye2bGBwlwH"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgQErJE4wlwH"
      },
      "source": [
        "Test the tokenizer encoding and decoding a simple sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfhFz44_wlwH"
      },
      "outputs": [],
      "source": [
        "sentence = \"What time is it, Tom?\"\n",
        "\n",
        "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "sentence_decoded = tokenizer.decode(\n",
        "        sentence_encoded[\"input_ids\"][0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "print('ENCODED SENTENCE:')\n",
        "print(sentence_encoded[\"input_ids\"][0])\n",
        "print('\\nDECODED SENTENCE:')\n",
        "print(sentence_decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_xnEUsrwlwH"
      },
      "source": [
        "<a name='7.2'></a>\n",
        "### 7.2 - Summarize Dialogue without Prompt Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckjS9OgNwlwH"
      },
      "source": [
        "Now it's time to explore how well the base LLM summarizes a dialogue without any prompt engineering. **Prompt engineering** is an act of a human changing the **prompt** (input) to improve the response for a given task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFQSkvhVwlwH"
      },
      "outputs": [],
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    inputs = tokenizer(dialogue, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{dialogue}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx8rbS_vwlwH"
      },
      "source": [
        "You can see that the guesses of the model make some sense, but it doesn't seem to be sure what task it is supposed to accomplish. Seems it just makes up the next sentence in the dialogue. Prompt engineering can help here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXnPiODkwlwH"
      },
      "source": [
        "<a name='7.3'></a>\n",
        "### 7.3 - Summarize Dialogue with an Instruction Prompt\n",
        "\n",
        "Prompt engineering is an important concept in using foundation models for text generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJDMNIk9wlwI"
      },
      "source": [
        "<a name='7.3.1'></a>\n",
        "#### 7.3.1 - Zero Shot Inference with an Instruction Prompt\n",
        "\n",
        "In order to instruct the model to perform a task - summarize a dialogue - you can take the dialogue and convert it into an instruction prompt. This is often called **zero shot inference**.\n",
        "\n",
        "Wrap the dialogue in a descriptive instruction and see how the generated text will change:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhIDUGv8wlwI"
      },
      "outputs": [],
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation in an informative way.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "TL;DR:\n",
        "    \"\"\"\n",
        "\n",
        "    # Input constructed prompt instead of the dialogue.\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{prompt}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeCN2HHfwlwI"
      },
      "source": [
        "This is much better! But the model still does not pick up on the nuance of the conversations though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3ImQ_hJwlwI"
      },
      "source": [
        "**Exercise:**\n",
        "\n",
        "- Experiment with the `prompt` text and see how the inferences will be changed. Will the inferences change if you end the prompt with just empty string vs. `Summary: `?\n",
        "- Try to rephrase the beginning of the `prompt` text from `Summarize the following conversation.` to something different - and see how it will influence the generated output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO"
      ],
      "metadata": {
        "id": "grFHKj2Fjk4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh_9ZpNKwlwI"
      },
      "source": [
        "<a name='7.3.2'></a>\n",
        "#### 7.3.2 - Zero Shot Inference with the Prompt Template from FLAN-T5\n",
        "\n",
        "Let's use a slightly different prompt. FLAN-T5 has many prompt templates that are published for certain tasks [here](https://github.com/google-research/FLAN/tree/main/flan/v2). In the following code, you will use one of the [pre-built FLAN-T5 prompts](https://github.com/google-research/FLAN/blob/main/flan/v2/templates.py):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syjz0MJbwlwI"
      },
      "outputs": [],
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{prompt}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWGsEVkawlwI"
      },
      "source": [
        "Notice that this prompt from FLAN-T5 did help a bit, but still struggles to pick up on the nuance of the conversation. This is what you will try to solve with the few shot inferencing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0QSI0JXwlwI"
      },
      "source": [
        "<a name='7.4'></a>\n",
        "### 7.4 - Summarize Dialogue with One Shot and Few Shot Inference\n",
        "\n",
        "**One shot and few shot inference** are the practices of providing an LLM with either one or more full examples of prompt-response pairs that match your task - before your actual prompt that you want completed. This is called \"in-context learning\" and puts your model into a state that understands your specific task.  You can read more about it in [this blog from HuggingFace](https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWl0HTgawlwI"
      },
      "source": [
        "<a name='7.4.1'></a>\n",
        "#### 7.4.1 - One Shot Inference\n",
        "\n",
        "Let's build a function that takes a list of `example_indices_full`, generates a prompt with full examples, then at the end appends the prompt which you want the model to complete (`example_index_to_summarize`).  You will use the same FLAN-T5 prompt template from Section [7.2](#7.2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe-efkh4wlwI"
      },
      "outputs": [],
      "source": [
        "def make_prompt(example_indices_full, example_index_to_summarize):\n",
        "    prompt = ''\n",
        "    for index in example_indices_full:\n",
        "        dialogue = dataset['test'][index]['dialogue']\n",
        "        summary = dataset['test'][index]['summary']\n",
        "\n",
        "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
        "        prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "{summary}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "\"\"\"\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49AQj8skwlwI"
      },
      "source": [
        "Construct the prompt to perform one shot inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lze6p-N2wlwI"
      },
      "outputs": [],
      "source": [
        "example_indices_full = [40]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(one_shot_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxIw4r1ewlwI"
      },
      "source": [
        "Now pass this prompt to perform the one shot inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfn3Q_8JwlwI"
      },
      "outputs": [],
      "source": [
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhZC16fgwlwI"
      },
      "source": [
        "<a name='7.4.2'></a>\n",
        "#### 7.4.2 - Few Shot Inference\n",
        "\n",
        "Let's explore few shot inference by adding two more full dialogue-summary pairs to your prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X0SbtH0wlwI"
      },
      "outputs": [],
      "source": [
        "example_indices_full = [40, 80, 120]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(few_shot_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZT4s9D7wlwJ"
      },
      "source": [
        "Now pass this prompt to perform a few shot inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDFJMJPhwlwJ"
      },
      "outputs": [],
      "source": [
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1aHUBziwlwJ"
      },
      "source": [
        "<a name='8'></a>\n",
        "## üë®‚Äçüíª 8 - Summarize Dialogue with Parameter Efficient Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP23dkLFwlwJ"
      },
      "source": [
        "In this part of the notebook, you will fine-tune an existing LLM from Hugging Face for enhanced dialogue summarization. As before, you will use the [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5) model, which provides a high quality instruction tuned model and can summarize text out of the box. To improve the inferences, you will explore a full fine-tuning approach and evaluate the results with ROUGE metrics. Then you will perform **Parameter Efficient Fine-Tuning (PEFT)** and evaluate the resulting model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh9Mh9ybwlwJ"
      },
      "source": [
        "Now install the required packages for the LLM and datasets.\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5JZ25vcmUgdGhlIHdhcm5pbmdzIGFuZCBlcnJvcnMsIGFsb25nIHdpdGggdGhlIG5vdGUgYWJvdXQgcmVzdGFydGluZyB0aGUga2VybmVsIGF0IHRoZSBlbmQuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ciShi8NDwlwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9fb8a0-e4f2-457d-9f73-c7ba40b3b6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.0.1\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.3.0a0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchdata==0.5.1 (from versions: 0.3.0a1, 0.3.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchdata==0.5.1\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "trl 0.15.2 requires transformers>=4.46.0, but you have transformers 4.27.2 which is incompatible.\n",
            "unsloth-zoo 2025.2.7 requires peft!=0.11.0,>=0.7.1, but you have peft 0.3.0 which is incompatible.\n",
            "unsloth-zoo 2025.2.7 requires transformers>=4.46.1, but you have transformers 4.27.2 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install gdown\n",
        "%pip install --disable-pip-version-check \\\n",
        "    torch==1.13.1 \\\n",
        "    torchdata==0.5.1 --quiet\n",
        "\n",
        "%pip install \\\n",
        "    transformers==4.27.2 \\\n",
        "    datasets==3.0.1 \\\n",
        "    evaluate==0.4.0 \\\n",
        "    rouge_score==0.1.2 \\\n",
        "    loralib==0.1.1 \\\n",
        "    peft==0.3.0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5KR8Ay7wlwJ"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> RESTART THE ENVIRONMENT"
      ],
      "metadata": {
        "id": "JmoAXzOPRNYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LImeRBmCwlwJ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8NljtI_wlwK"
      },
      "source": [
        "Load the pre-trained base version of [FLAN-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5) and its tokenizer directly from HuggingFace. Setting `torch_dtype=torch.bfloat16` specifies the memory type to be used by this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWD4POFrwlwK"
      },
      "outputs": [],
      "source": [
        "model_name='google/flan-t5-base'\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
        "                                                       torch_dtype=torch.bfloat16).to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,use_fast=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Zw9Y59wlwK"
      },
      "source": [
        "It is possible to pull out the number of model parameters and find out how many of them are trainable. The following function can be used to do that, at this stage, you do not need to go into details of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPMJFvoywlwK"
      },
      "outputs": [],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(original_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5G7g_-MwlwJ"
      },
      "source": [
        "<a name='8.1'></a>\n",
        "### 8.1 - Preprocess the Dialogue-Summary Dataset\n",
        "\n",
        "You are going to continue experimenting with the [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) dataset. It contains 10,000+ dialogues with the corresponding manually labeled summaries and topics.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrPtjaJHwlwK"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
        "    end_prompt = '\\n\\nSummary: '\n",
        "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the dataset."
      ],
      "metadata": {
        "id": "q2cFGtK0VNAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)"
      ],
      "metadata": {
        "id": "c7BI4nltRbrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZiT7_1pwlwK"
      },
      "source": [
        "To save some time in the lab, you will subsample the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XzWZvYVwlwK"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOzrYg_qwlwK"
      },
      "source": [
        "Check the shapes of all three parts of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKPOt2QvwlwK"
      },
      "outputs": [],
      "source": [
        "print(f\"Shapes of the datasets:\")\n",
        "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
        "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
        "\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLWunbNwlwK"
      },
      "source": [
        "The output dataset is ready for fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk2MIIzqwlwK"
      },
      "source": [
        "### 8.2 Full Fine-tuning of Small LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T82ZYBuDwlwK"
      },
      "source": [
        "<a name='8.2.1'></a>\n",
        "#### 8.2.1 - Fine-tune the Model with the Pre-processed Dataset\n",
        "\n",
        "Now utilize the built-in Hugging Face `Trainer` class (see the documentation [here](https://huggingface.co/docs/transformers/main_classes/trainer)). Pass the preprocessed dataset with reference to the original model. Other training parameters are found experimentally and there is no need to go into details about those at the moment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgwIrZpVwlwK"
      },
      "source": [
        "Let's set the training hyperparameters. You can tweak them to affect the effectiveness of the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1qccSI8wlwK"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 1e-5\n",
        "WEIGHT_DECAY=1e-2\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "NUM_TRAIN_EPOCHS = 1\n",
        "\n",
        "# let's keep the training iteration low for the sake of fast experiments during the lab\n",
        "MAX_STEPS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHMG3YMIwlwK"
      },
      "outputs": [],
      "source": [
        "output_dir = f'./dialogue-summary-training-{str(int(time.time()))}'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    logging_steps=1,\n",
        "    max_steps=MAX_STEPS,\n",
        "    per_device_train_batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=original_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31D7DltCwlwK"
      },
      "source": [
        "Start training process...\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5Zb3UgY2FuIHNhZmVseSBpZ25vcmUgdGhlIHdhcm5pbmcgbWVzc2FnZXMuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAkzCw1xwlwK"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMSo0EgowlwL"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqgX6ddPwlwL"
      },
      "source": [
        "Training a fully fine-tuned version of the model would take a few hours on a GPU. To save time, download a checkpoint of the fully fine-tuned model to use in the rest of this notebook. This fully fine-tuned model will also be referred to as the **instruct model** in this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ_o8BCCwlwL"
      },
      "outputs": [],
      "source": [
        "instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"disi-unibo-nlp/flan-T5-dialogsum\",\n",
        "                                                       torch_dtype=torch.bfloat16).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIANujHYwlwL"
      },
      "source": [
        "<a name='8.2.2'></a>\n",
        "#### 8.2.2 - Model Evaluation\n",
        "Let's now evaluate the model performances before and after fine-tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arwstfLUwlwL"
      },
      "source": [
        "##### 8.2.2.1 Human Evaluation\n",
        "\n",
        "As with many GenAI applications, a qualitative approach where you ask yourself the question \"Is my model behaving the way it is supposed to?\" is usually a good starting point. In the example below (the same one we started this notebook with), you can see how the fine-tuned model is able to create a reasonable summary of the dialogue compared to the original inability to understand what is being asked of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfQu8zGowlwL"
      },
      "outputs": [],
      "source": [
        "index = 200\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "human_baseline_summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZndiRTlwlwL"
      },
      "source": [
        "<a name='8.2.2.2'></a>\n",
        "##### 8.2.2.2 - ROUGE Evaluation\n",
        "\n",
        "We can now use a precise automatic metric like ROUGE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzbRH1JdwlwL"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0_HWcL3wlwL"
      },
      "source": [
        "Generate the outputs for the sample of the test dataset (only 10 dialogues and summaries to save time), and save the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzaxmOy_wlwL"
      },
      "outputs": [],
      "source": [
        "dialogues = dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "\n",
        "for _, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIEPs__AwlwM"
      },
      "source": [
        "Evaluate the models computing ROUGE metrics. Notice the improvement in the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7Qobm-JwlwM"
      },
      "outputs": [],
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gnF-LpPwlwM"
      },
      "source": [
        "The file `dialogue-summary-training-results.csv` contains a pre-populated list of all model results which you can use to evaluate on a larger section of data. Let's do that for each of the models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg0CKAkUwlwM"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjIuG27cwlwM"
      },
      "outputs": [],
      "source": [
        "!gdown --id 1UIJckFttxgj81EhqZlQGXUv5-dcoD7vy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJVGXunhwlwM"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv(\"dialogue-summary-training-results.csv\")\n",
        "\n",
        "human_baseline_summaries = results['human_baseline_summaries'].values\n",
        "original_model_summaries = results['original_model_summaries'].values\n",
        "instruct_model_summaries = results['instruct_model_summaries'].values\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtsFPbLwlwM"
      },
      "source": [
        "The results show substantial improvement in all ROUGE metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHIiw3vfwlwM"
      },
      "outputs": [],
      "source": [
        "print(\"Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(instruct_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(instruct_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDJ0P32qwlwM"
      },
      "source": [
        "<a name='8.3'></a>\n",
        "### 8.3 - Parameter Efficient Fine-Tuning with LoRA\n",
        "\n",
        "Now, let's perform **Parameter Efficient Fine-Tuning (PEFT)** fine-tuning as opposed to \"full fine-tuning\" as you did above.\n",
        "\n",
        "**PEFT** is a form of instruction fine-tuning that is much more efficient than full fine-tuning - with comparable evaluation results as you will see soon. PEFT is a generic term indicating a family of techniques. It includes **Low-Rank Adaptation (LoRA)** and prompt tuning (<u>which is NOT THE SAME as prompt engineering!</u>).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_Sx6W5NwlwN"
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1w5BoyVcpkYrXcD_2vczTcQBC8cwTXico\" alt=\"LoRA on Attention Layers\" width=\"1200\"/>\n",
        "</p>\n",
        "\n",
        "> From [\"Evaluating Parameter-Efficient Transfer Learning Approaches on SURE Benchmark for Speech Understanding\"](https://arxiv.org/abs/2303.03267)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuN0-GowwlwN"
      },
      "source": [
        "[**LoRA**](https://arxiv.org/abs/2106.09685) fine-tunes models by **introducing additional low-rank matrices into specific layers** of a pre-trained language model. Instead of updating the entire weight matrix during training, **LoRA injects two small trainable matrices that approximate the weight updates**, while the original weights remain frozen. This setup effectively learns task-specific information through these low-rank updates, while maintaining the integrity of the pre-trained model.\n",
        "\n",
        "</br>\n",
        "\n",
        "These lower rank matrices--called **adapters**--flank the pre-trained weight matrices $W$ and lay on their embedded knwoledge for the new domain adaptaion:\n",
        "$$\n",
        "\\mathbf{W} \\in \\mathbb{R}^{d \\times d} \\approx \\mathbb{R}^{d \\times r} \\ni \\mathbf{W_A \\times W_B} \\in \\mathbb{R}^{r \\times d}\n",
        "$$\n",
        "with $r$ being the **rank** which regulates the reduction in number of trainable parameters while preserving the original input and output shapes.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOW5plKBuMlGgpD0SO8nZA.png\" alt=\"T5 Fine-Tuning\" width=\"900\"/>\n",
        "</p>\n",
        "\n",
        "\n",
        "The core idea behind LoRA is **decomposing the weight updates into smaller components**, allowing efficient task-specific adaptation without needing to modify the entire model. This approach significantly reduces the number of parameters that need to be trained.\n",
        "\n",
        "\n",
        "> You will see this and other efficient training techniques more in details during the course. **Hang on!**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z26EL9JPwlwN"
      },
      "source": [
        "In most cases, when someone says PEFT, they typically mean LoRA. LoRA, at a very high level, **allows the user to fine-tune their model using fewer compute resources (in some cases, a single GPU)**. After fine-tuning for a specific task, use case, or tenant with LoRA, the result is that the original LLM remains unchanged and a newly-trained ‚ÄúLoRA adapter‚Äù emerges. **This LoRA adapter is much, much smaller than the original LLM - on the order of a single-digit % of the original LLM size (MBs vs GBs)**.  \n",
        "\n",
        "</br>\n",
        "\n",
        "That said, at inference time, the LoRA adapter needs to be reunited and combined with its original LLM to serve the inference request. The benefit, however, is that many LoRA adapters can re-use the original LLM which reduces overall memory requirements when serving multiple tasks and use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> If you‚Äôre wondering whether your memory is sufficient for fine-tuning a model, check it out [here](https://huggingface.co/spaces/Vokturz/can-it-run-llm)."
      ],
      "metadata": {
        "id": "prQkhYKKKzps"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvIWnulCwlwN"
      },
      "source": [
        "<a name='8.3.1'></a>\n",
        "#### 8.3.1 - Train the Adapters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQrXwS38wlwN"
      },
      "source": [
        "You need to set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained.\n",
        "\n",
        "</br>\n",
        "\n",
        "Adapters can be applied wherever desired, however it is good practice to apply them to linear layers for stability reasons during fine-tuning and to avoid phenomena such as *catastrophic forgetting*. In our experiments we will target the **query** and **value** projection matrices in the attention layers throughout the whole archtecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MXABdYSBwlwN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "0ff9baa3-8a05-483f-8559-a9b397d25c74"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'PeftConfig' from 'peft.utils' (/usr/local/lib/python3.11/dist-packages/peft/utils/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-74e5b253aef4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoraConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m             \u001b[0;31m# regulates adapters dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLORA_ALPHA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m       \u001b[0;31m# scaling factors for the intialization of adapters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.3.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPEFT_TYPE_TO_CONFIG_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_peft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m from .peft_model import (\n\u001b[1;32m     24\u001b[0m     \u001b[0mPeftModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/mapping.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from .peft_model import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mPeftModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mPeftModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mPromptEncoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 39\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mTRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'PeftConfig' from 'peft.utils' (/usr/local/lib/python3.11/dist-packages/peft/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "\n",
        "RANK = 32             # regulates adapters dimension\n",
        "LORA_ALPHA = 32       # scaling factors for the intialization of adapters\n",
        "LORA_DROPOUT = 0.05   # dropout factor for the LoRA layers\n",
        "\n",
        "TARGET_LAYERS = [\"q\", \"v\"]\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=RANK,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=TARGET_LAYERS,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # define the model's architecture\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZR1aqZTwlwN"
      },
      "source": [
        "Add LoRA adapter layers/parameters to the original LLM to be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJeCrTQ6wlwN"
      },
      "outputs": [],
      "source": [
        "peft_model = get_peft_model(original_model,\n",
        "                            lora_config)\n",
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_BPVPvuwlwN"
      },
      "source": [
        "üòß <u>We are just training **1.4%** of the total parameters!!</u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--RMtMlbwlwN"
      },
      "source": [
        "Define training arguments and create `Trainer` instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC88nABcwlwN"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 1e-3 # Higher learning rate than full fine-tuning.\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "NUM_TRAIN_EPOCHS = 1\n",
        "MAX_STEPS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df2I9IQTwlwN"
      },
      "outputs": [],
      "source": [
        "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "    logging_steps=1,\n",
        "    max_steps=MAX_STEPS,\n",
        "    per_device_train_batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7sYbcTgwlwN"
      },
      "source": [
        "Now everything is ready to train the PEFT adapter and save the model.\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qUfa6dzwlwN"
      },
      "outputs": [],
      "source": [
        "peft_trainer.train()\n",
        "\n",
        "peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
        "\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnX1LYsTwlwN"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1dqzfm-wlwN"
      },
      "source": [
        "That training was performed on a subset of data. To load a fully trained PEFT model, read a checkpoint of a PEFT model from our HuggingFace repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfASfG82wlwN"
      },
      "source": [
        "Prepare this model by adding an adapter to the original FLAN-T5 model. You are setting `is_trainable=False` because the plan is only to perform inference with this PEFT model. If you were preparing the model for further training, you would set `is_trainable=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH9kNdbCwlwN"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
        "                                       'disi-unibo-nlp/flan-T5-base-dialogsum-adapters',\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainable=False).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gunsWS-uwlwN"
      },
      "source": [
        "You can see here the T5 model structure augmented with adapters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2t7yeqDwlwN",
        "outputId": "88f78c8f-0121-4cb9-a6bf-6e0ad0989269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 768)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (2): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (3): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (4): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (5): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (6): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (7): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (8): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (9): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (10): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (11): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (2): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (3): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (4): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (5): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (6): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (7): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (8): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (9): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (10): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (11): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "peft_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JIo2FfxwlwN"
      },
      "source": [
        "The number of trainable parameters will be `0` due to `is_trainable=False` setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJwDsF21wlwN",
        "outputId": "9b44da12-9d28-46e1-f097-40dbfb8d7a64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 0 || all params: 251116800 || trainable%: 0.0\n"
          ]
        }
      ],
      "source": [
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE7qTBKJwlwO"
      },
      "source": [
        "<a name='8.3.2'></a>\n",
        "#### 8.3.2 - Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GkhP12uwlwO"
      },
      "source": [
        "<a name='8.3.2.1'></a>\n",
        "##### 8.3.2.1 - Human Evaluation\n",
        "\n",
        "Make inferences for the same example as in Section [8.2.2.1](#8.2.2.1), with the original model, fully fine-tuned and PEFT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8yAKMh8wlwP",
        "outputId": "eec88e06-e32e-4aff-ea44-6972879bd938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "ORIGINAL MODEL:\n",
            "You're going to be upgrading your computer system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INSTRUCT MODEL:\n",
            "#Person1# suggests #Person2# upgrading #Person2#'s system, hardware, and CD-ROM drive. #Person2# thinks it's great.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "PEFT MODEL: #Person1# recommends adding a painting program to #Person2#'s software and upgrading hardware. #Person2# also wants to upgrade the hardware because it's outdated now.\n"
          ]
        }
      ],
      "source": [
        "index = 200\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "baseline_human_summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'PEFT MODEL: {peft_model_text_output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQVPEX5iwlwP"
      },
      "source": [
        "<a name='8.3.2.2'></a>\n",
        "##### 8.3.2.2 - ROUGE Evaluation\n",
        "\n",
        "Perform inferences for the sample of the test dataset (only 10 dialogues and summaries to save time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tj49tngwlwP",
        "outputId": "ad80e131-75cc-41a8-e03a-0d027940da5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
              "1  In order to prevent employees from wasting tim...   \n",
              "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
              "3  #Person2# arrives late because of traffic jam....   \n",
              "4  #Person2# decides to follow #Person1#'s sugges...   \n",
              "5  #Person2# complains to #Person1# about the tra...   \n",
              "6  #Person1# tells Kate that Masha and Hero get d...   \n",
              "7  #Person1# tells Kate that Masha and Hero are g...   \n",
              "8  #Person1# and Kate talk about the divorce betw...   \n",
              "9  #Person1# and Brian are at the birthday party ...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  The Office of the President and CEO is requiri...   \n",
              "1  The following memo is to be distributed to all...   \n",
              "2                      This is an intra-office memo.   \n",
              "3                          The person is a commuter.   \n",
              "4  I'm finally here. I'm stuck in traffic. I'm st...   \n",
              "5                               You're finally here.   \n",
              "6               Masha and Hero are getting divorced.   \n",
              "7               Masha and Hero are getting divorced.   \n",
              "8               Masha and Hero are getting divorced.   \n",
              "9                         Brian's birthday is today.   \n",
              "\n",
              "                            instruct_model_summaries  \\\n",
              "0  #Person1# asks Ms. Dawson to take a dictation ...   \n",
              "1  #Person1# asks Ms. Dawson to take a dictation ...   \n",
              "2  #Person1# asks Ms. Dawson to take a dictation ...   \n",
              "3  #Person2# got stuck in traffic again. #Person1...   \n",
              "4  #Person2# got stuck in traffic again. #Person1...   \n",
              "5  #Person2# got stuck in traffic again. #Person1...   \n",
              "6  Masha and Hero are getting divorced. Kate can'...   \n",
              "7  Masha and Hero are getting divorced. Kate can'...   \n",
              "8  Masha and Hero are getting divorced. Kate can'...   \n",
              "9  Brian's birthday is coming. #Person1# invites ...   \n",
              "\n",
              "                                peft_model_summaries  \n",
              "0  #Person1# asks Ms. Dawson to take a dictation ...  \n",
              "1  #Person1# asks Ms. Dawson to take a dictation ...  \n",
              "2  #Person1# asks Ms. Dawson to take a dictation ...  \n",
              "3  #Person2# got stuck in traffic and #Person1# s...  \n",
              "4  #Person2# got stuck in traffic and #Person1# s...  \n",
              "5  #Person2# got stuck in traffic and #Person1# s...  \n",
              "6  Kate tells #Person2# Masha and Hero are gettin...  \n",
              "7  Kate tells #Person2# Masha and Hero are gettin...  \n",
              "8  Kate tells #Person2# Masha and Hero are gettin...  \n",
              "9  Brian remembers his birthday and invites #Pers...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fed6b832-93e3-4f98-b973-f9473cd8f273\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "      <th>peft_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
              "      <td>The Office of the President and CEO is requiri...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In order to prevent employees from wasting tim...</td>\n",
              "      <td>The following memo is to be distributed to all...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
              "      <td>This is an intra-office memo.</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Person2# arrives late because of traffic jam....</td>\n",
              "      <td>The person is a commuter.</td>\n",
              "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
              "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
              "      <td>I'm finally here. I'm stuck in traffic. I'm st...</td>\n",
              "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
              "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
              "      <td>You're finally here.</td>\n",
              "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
              "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
              "      <td>Masha and Hero are getting divorced.</td>\n",
              "      <td>Masha and Hero are getting divorced. Kate can'...</td>\n",
              "      <td>Kate tells #Person2# Masha and Hero are gettin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
              "      <td>Masha and Hero are getting divorced.</td>\n",
              "      <td>Masha and Hero are getting divorced. Kate can'...</td>\n",
              "      <td>Kate tells #Person2# Masha and Hero are gettin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
              "      <td>Masha and Hero are getting divorced.</td>\n",
              "      <td>Masha and Hero are getting divorced. Kate can'...</td>\n",
              "      <td>Kate tells #Person2# Masha and Hero are gettin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
              "      <td>Brian's birthday is today.</td>\n",
              "      <td>Brian's birthday is coming. #Person1# invites ...</td>\n",
              "      <td>Brian remembers his birthday and invites #Pers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fed6b832-93e3-4f98-b973-f9473cd8f273')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fed6b832-93e3-4f98-b973-f9473cd8f273 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fed6b832-93e3-4f98-b973-f9473cd8f273');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b28b8bfc-d3de-45c9-9baa-f1ef8b6124ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b28b8bfc-d3de-45c9-9baa-f1ef8b6124ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b28b8bfc-d3de-45c9-9baa-f1ef8b6124ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3c224fed-8833-4ed9-b35b-18d2a53f0a65\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3c224fed-8833-4ed9-b35b-18d2a53f0a65 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"human_baseline_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"#Person1# and Kate talk about the divorce between Masha and Hero. Kate feels surprised because she thought they are well matched\",\n          \"In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.\",\n          \"#Person2# complains to #Person1# about the traffic jam, #Person1# suggests quitting driving and taking public transportation instead.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"The following memo is to be distributed to all employees:\",\n          \"You're finally here.\",\n          \"The Office of the President and CEO is requiring employees to take a dictation before they may communicate with each other.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruct_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"#Person2# got stuck in traffic again. #Person1# suggests #Person2# start taking public transport system to work and suggests #Person2# start biking to work when it's nicer outside. #Person2# agrees.\",\n          \"Brian's birthday is coming. #Person1# invites Brian to have a dance and Brian compliments #Person1#'s looks. Brian thinks #Person1# looks great and invites #Person1# to have a drink together.\",\n          \"#Person1# asks Ms. Dawson to take a dictation to all employees by this afternoon. Ms. Dawson tells #Person1# all office communications are restricted to email correspondence and official memos and the use of Instant Message programs by employees during working hours is strictly prohibited. #Person1# wants to change the communication methods and Ms. Dawson tells #Person1# it applies to internal and external communications.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peft_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"#Person2# got stuck in traffic and #Person1# suggests #Person2# start taking public transport system to work. #Person2# thinks it's better for the environment and #Person2# will miss having freedom with a car. #Person1# suggests biking to work when it's nicer outside.\",\n          \"Brian remembers his birthday and invites #Person1# to the party. Brian is popular with everyone and looks pretty today. #Person1# and Brian will have a drink together to celebrate Brian's birthday.\",\n          \"#Person1# asks Ms. Dawson to take a dictation to all employees by this afternoon. Ms. Dawson tells #Person1# that all office communications are restricted to email correspondence and official memos. #Person1# wants to change the communication methods and asks Ms. Dawson to get the memo typed up and distributed to all employees before 4 pm.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dialogues = dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "peft_model_summaries = []\n",
        "\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "    human_baseline_text_output = human_baseline_summaries[idx]\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "    peft_model_summaries.append(peft_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtDbG4FtwlwP"
      },
      "source": [
        "Compute ROUGE score for this subset of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o9_AlxHwlwP",
        "outputId": "1d3afcc9-87a6-44f2-c791-ec7a89767739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.2251650450998277, 'rouge2': 0.08266666666666667, 'rougeL': 0.19062610497393107, 'rougeLsum': 0.19391456369717236}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': 0.41026607717457186, 'rouge2': 0.17840645241958838, 'rougeL': 0.2977022096267017, 'rougeLsum': 0.2987374187518165}\n",
            "PEFT MODEL:\n",
            "{'rouge1': 0.3725351062275605, 'rouge2': 0.12138811933618107, 'rougeL': 0.27620639623170606, 'rougeLsum': 0.2758134870822362}\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3sOFN7SwlwP"
      },
      "source": [
        "> Notice, that PEFT model results are not too bad, while the training process was much easier!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Jtzu1JwlwP"
      },
      "source": [
        "You already computed ROUGE score on the full dataset, after loading the results from the `data/dialogue-summary-training-results.csv` file. Load the values for the PEFT model now and check its performance compared to other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrZIpy0PwlwP",
        "outputId": "144c7baa-4607-4d53-d332-9848af51347d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.2334158581572823, 'rouge2': 0.07603964187010573, 'rougeL': 0.20145520923859048, 'rougeLsum': 0.20145899339006135}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': 0.42161291557556113, 'rouge2': 0.18035380596301792, 'rougeL': 0.3384439349963909, 'rougeLsum': 0.33835653595561666}\n",
            "PEFT MODEL:\n",
            "{'rouge1': 0.40810631575616746, 'rouge2': 0.1633255794568712, 'rougeL': 0.32507074586565354, 'rougeLsum': 0.3248950182867091}\n"
          ]
        }
      ],
      "source": [
        "human_baseline_summaries = results['human_baseline_summaries'].values\n",
        "original_model_summaries = results['original_model_summaries'].values\n",
        "instruct_model_summaries = results['instruct_model_summaries'].values\n",
        "peft_model_summaries     = results['peft_model_summaries'].values\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjLNBY3RwlwP"
      },
      "source": [
        "The results show less of an improvement over full fine-tuning, but the benefits of PEFT typically outweigh the slightly-lower performance metrics.\n",
        "\n",
        "Calculate the improvement of PEFT over the original model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETz20J9awlwP",
        "outputId": "802d75c5-6c3a-4c0f-ea04-22a9e1a49d1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\n",
            "rouge1: 17.47%\n",
            "rouge2: 8.73%\n",
            "rougeL: 12.36%\n",
            "rougeLsum: 12.34%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkl2PYbwlwP"
      },
      "source": [
        "Now calculate the improvement of PEFT over a full fine-tuned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjs-ZC_twlwP",
        "outputId": "731d3f1a-c50b-483b-d4ed-77329f048587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\n",
            "rouge1: -1.35%\n",
            "rouge2: -1.70%\n",
            "rougeL: -1.34%\n",
            "rougeLsum: -1.35%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01VSpLVpwlwP"
      },
      "source": [
        "Here you see a small percentage decrease in the ROUGE metrics vs. full fine-tuned. However, the training requires much less computing and memory resources (often just a single GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8e7VcQwwlwP"
      },
      "source": [
        "<a name='8.4'></a>\n",
        "### 8.4 - Finetuning big LLMs with Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMwOYLd0wlwP"
      },
      "source": [
        "In this section we will finetune a (very) Large Language Model <u>on Colab</u> with the amazing ü¶• **Unsloth** library. Thanks to an optimized memory management of the transformer's internal information, this library allows you to finetune models on small GPUs, reaching a x2 inference performance boost."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you prefer, to avoid dealing with library version errors, you can now delete your current run-time and create a new one. Then install the following packages.\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5JZ25vcmUgdGhlIHdhcm5pbmdzIGFuZCBlcnJvcnMsIGFsb25nIHdpdGggdGhlIG5vdGUgYWJvdXQgcmVzdGFydGluZyB0aGUga2VybmVsIGF0IHRoZSBlbmQuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
      ],
      "metadata": {
        "id": "HO-IuejPPNVM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1b-BHK7iwlwP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install trl bitsandbytes\n",
        "!pip install evaluate rouge_score\n",
        "!pip install unsloth\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ],
      "metadata": {
        "id": "KUs_vlAocCoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> RESTART THE ENVIRONMENT"
      ],
      "metadata": {
        "id": "C4flNeE4bH2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "from evaluate import load\n",
        "from tqdm import tqdm\n",
        "\n",
        "rouge = load(\"rouge\")"
      ],
      "metadata": {
        "id": "FSeFQo1VY-8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72cbeaa-ef43-47c6-ce71-d025c8e19ee1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-22ac0e07b4d7>:3: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import is_bfloat16_supported\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also define a util function to perform parallel generation using batches. For our tests we shall use a simple and direct instruction prompt."
      ],
      "metadata": {
        "id": "5UEEoE-ePhEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are a helpful assistant. Your task is to summarize the texts provided by the user.\n",
        "Answer directly with no prehamble or comment.\n",
        "Be precise and concise.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_outputs_in_batches(model,\n",
        "                                tokenizer,\n",
        "                                dataset,\n",
        "                                batch_size : int = 16,\n",
        "                                max_length : int = 512,\n",
        "                                max_new_tokens : int = 256,\n",
        "                                device : str = \"cuda\"):\n",
        "\n",
        "    # Enable native 2x faster inference\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "\n",
        "    texts = dataset[\"dialogue\"]\n",
        "\n",
        "    # Calculate the number of batches\n",
        "    num_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "\n",
        "    generated_outputs = []\n",
        "    for i in tqdm(range(num_batches)):\n",
        "        this_batch = texts[i * batch_size:(i + 1) * batch_size]\n",
        "\n",
        "        # prompt the data into a conversation-like input\n",
        "        batch_texts = []\n",
        "        for txt in this_batch:\n",
        "          msg = [\n",
        "              {\n",
        "                  \"role\" : \"system\",\n",
        "                  \"content\" : SYSTEM_PROMPT\n",
        "              },\n",
        "              {\n",
        "                  \"role\" : \"user\",\n",
        "                  \"content\" : txt\n",
        "              }\n",
        "          ]\n",
        "          msg_prompted = tokenizer.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n",
        "          batch_texts.append(msg_prompted)\n",
        "\n",
        "        inputs = tokenizer(batch_texts,\n",
        "                           padding=True,\n",
        "                           return_tensors=\"pt\",\n",
        "                           max_length=max_length,\n",
        "                           truncation=True).to(device)\n",
        "\n",
        "        # Let's use greedy decoding\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.2,\n",
        "            use_cache=True\n",
        "        )\n",
        "\n",
        "        # Decode the generated outputs into human-readable text\n",
        "        decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "        # post-process outputs to remove special tokens\n",
        "        parsed_dec_outs = []\n",
        "        for out in decoded_outputs:\n",
        "          parsed_dec_outs.append(out.split(\"assistant\")[-1].strip())\n",
        "\n",
        "        generated_outputs.extend(parsed_dec_outs)\n",
        "\n",
        "    return generated_outputs"
      ],
      "metadata": {
        "id": "wXg_KAmUjGVN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Train\"></a>\n",
        "#### 8.4.1 Load Dataset and Model"
      ],
      "metadata": {
        "id": "7YV1yqw25ox_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download (again) the `dialogsum` dataset and format it."
      ],
      "metadata": {
        "id": "C3GATO8HRn0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "e88925bf36484e0db791e7494326bb7e",
            "a701e02fcac549af90641931120cba59",
            "a25005e855844678b317c26910e459fc",
            "57e88807f37e45fcbe8c2cf9dadab5fc",
            "3f12bd1c86da4631ab7000ec831630f9",
            "b663509e4c18467281213284f1a23a37",
            "c668cd27725e4217a007a4defea3a6c6",
            "f49b34883443459d89941e3c4f2d55f9",
            "7d15d59d04404bf4843d3be612727242",
            "019cb223c953420883c1dcca34a15899",
            "ebf76eebd7bf4319bdfb0f7baf8ec1d6",
            "babda43599e54acfba0b83b63627cc72",
            "86bed4ab45ef462f8147853f6db31260",
            "3fa93757eee344f39a90bbdee77bcfd3",
            "e0a8d79745454fc7a90d58529da62c88",
            "898df6b7419748068b691956924655e1",
            "ccc73841d92341448d22106a6015f166",
            "de1a40ef02d046b7bc0d0b9bf97c07ac",
            "dc8d9cb250124d818909694d5f21d41b",
            "0026e5df70264de1bd095bdc86952f57",
            "a04e7df021a14d3490622baee7b744aa",
            "60255df60b7d417bb324e50404d09775",
            "6b750d0d49d646c49f3eb8f2a22272e7",
            "097f5a64be34490683c81dc4a1e23fa3",
            "6850fe780e83435ba572e34e2cef6a45",
            "2d3c087a46cf4661b26eee0d947a5c4b",
            "53fe8e9b274b47b3a8e29530b2662577",
            "fa928bf4bb60453da6fb447da8a14a59",
            "0f16fb5a985c4fd7a57054b5324d6572",
            "7006884a2e66499ba3ddc358dfccf61c",
            "525ec69ad09248aba6b96c26a7c145d8",
            "a2c5cfbb7b8d4992ae19610ff31fa335",
            "eb11591cb25544a9a3eab45c04aa2b50",
            "e49d06bbcd8b482f90aa903e1c70a412",
            "2f3cf5455c934448adcb4d07bad6a469",
            "ab438830d549420aada14a1c93fe1d99",
            "494fad0099564bda930ce7b1b458176f",
            "a739608c2bd14e7cad6bcc5878488641",
            "4bee9f0834704ad68906cf1a2ae2adfa",
            "09e49b40f66444da9e6e512375b75cc0",
            "1e268f4b80624908bce8929c390df0c3",
            "7338e40f20794077bf6d45534f734c82",
            "f85ad7840f734554906616adceb34b0f",
            "01982c7287c4406bb815d9cd2daff0c1",
            "ffb17b9ba50c4f0f9df06c0561b6192f",
            "0a04fa862d5146f8a9f3cb002b4e0ae0",
            "b1706c84058a42f4bb2a6fd3d157e82b",
            "472a91692c124e88be42def209fe0242",
            "5bd7b33cc5904f2796263fc956f93b8e",
            "844ab54d0925492cba4daa7a5e5aa836",
            "239bd5fe2c3645a8a498c794f87d3ff4",
            "b2e9615379d94b58bbd69da3fd8b48fa",
            "0afc45cb9cbb44cb951290995c095378",
            "222772e931d9462ca1f97232f8119fe0",
            "0221ef4d7bd7403fa5ac78ba155f2d93",
            "e83016e3726a4c56828a83711daf05cf",
            "49fd09e3468f4284ac7a16118fed3bf1",
            "9668cb7963d240e0a5a9953fb268de84",
            "a5b6fa61328745d496b5cd7b09601856",
            "36406d33813241f3b3fe7fd15fec5813",
            "216aa9f8c79e400fb1e29e84e361d353",
            "9680025a00104e658fd8c0373a501139",
            "c1190886eeb248018910f3691d35937d",
            "9a683ce0bf1043e9a56dfb2f0d5b5ce8",
            "63a1d08ed38148719c53b8eb8e884ea8",
            "2224035dd5cf4b4b9b18053f5ce7b6a4",
            "01c14d1cedf24450924e615188aff7c2",
            "191056bb15584737a0b19d27e35fdcbf",
            "4ea63a987bcc48ed93d116797c639533",
            "d72fb54e7772405dbfe8312c2b5138be",
            "ba6fc7067fa143759aa76b3f0c640a88",
            "b36bd1afaca94691a43304c36348f709",
            "e7f54468fa6342908de0f64cb4e7db57",
            "84174cd1a2f84d0697f34852457ef287",
            "6296027f74f6432e9cdc89ad7502b4ae",
            "e2d6b3d0e12944a596cc637bd97272d0",
            "6861427fe03f456488e523ce7fa48671"
          ]
        },
        "id": "bfqHujz5UBer",
        "outputId": "abcb8695-d598-40dc-f912-5fa66e8d7615"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e88925bf36484e0db791e7494326bb7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "babda43599e54acfba0b83b63627cc72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.csv:   0%|          | 0.00/442k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b750d0d49d646c49f3eb8f2a22272e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.csv:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e49d06bbcd8b482f90aa903e1c70a412"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffb17b9ba50c4f0f9df06c0561b6192f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e83016e3726a4c56828a83711daf05cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01c14d1cedf24450924e615188aff7c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can load the model. We will use `Llama-3.1-8B-Instruct` from Meta.\n",
        "\n",
        "**Why using and fine-tuning an Instruct model?**\n",
        "\n",
        "Instruct models, which undergo instruction tuning phases, offer distinct advantages for specific tasks. While base models, if fine-tuned, can lead to better results due to their greater flexibility, <mark>instruction-tuned models excel at following instructions out of the box</mark>. This makes them particularly suitable for controllable tasks like controllable summarization, where precise adherence to guidelines is crucial.\n",
        "\n",
        "For short training sessions focused on formatting writing styles rather than injecting new knowledge, using an instruction-tuned model can be the optimal choice."
      ],
      "metadata": {
        "id": "tGcjcsHTUKAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "8271479b57cb4185969aa2da174f3f32",
            "1fcf908078e242868efb35465c566aa9",
            "de0f3c47da504181af8f64d8059dfc65",
            "c61fd9461b62464c9f1c6838a74c029f",
            "becc8840afaa4dfb8f38f51e032f18d2",
            "5d25e9d158f044ecbd50a6599156e8a3",
            "a3d8fcc91f9e44a4ac40b0c8dc427128",
            "1b54a06220f14983855185a6e18b4f31",
            "7430332c9bf6429aa97c59163f521ba7",
            "0f1114f5053a40daaed73e404e24e65d",
            "81e87da1050c4170a0fa96bb48a4522e",
            "8e48942f409c4d8093e53095b21f6c44",
            "d4fc0efbfc344045b92134eadf05a054",
            "c59df812f9ee469d9428aa9ef45f1d61",
            "d894a71a0409440a8f55cbf8d026e243",
            "b0c2e0fbd03246a98495b858945ffd4b",
            "b1855598c14f4a72a90e7542892b6cbb",
            "8d465c474c354ff28784b18e111687f0",
            "a42eb1ebc01a4fa79f5a7302b8d5be37",
            "3b32591330724003a46c8ae77cd77582",
            "420cff2fe4fc40cc976d70ecd576494e",
            "ada5fe7927234379b6c54d80b988207f",
            "c4ead6264bf64d53917b767030e3b2f3",
            "4f626710ce09438c83001791bdad6bf7",
            "d39cf0ac395f4b4ea537f11811991b86",
            "f089d8561f924ab8a2330421baa648f3",
            "a4ca1d91643e4ca5afd4786f475b48c9",
            "385438e87d2a4767abf524e31422dc2f",
            "d440593cad314701b437f5391adc774c",
            "21ff1e37449549a1ba575473c85d2693",
            "4f2d923722274b98888346a87c34909d",
            "32ea473d7874408eaad9ad564299a275",
            "a0525bd3d86e48959b4b23b50debd18a",
            "2aa40c7bfb424e3883616a036ac3b44c",
            "590e63ff3c834212b5b489755fef80b0",
            "18ac4905e40c458e8c010719a9b98f4b",
            "63136f7ba9134bb4a78081aba2461561",
            "a04208e6556f4834a2245204ddd2bbb1",
            "4b485fee302d4b65adc839bbbcff63ba",
            "f56998a87db6481bb44ef7c53515b1a7",
            "4664a35431864a1db92ee615102c91a3",
            "5881ba86c49d4a3e8e71af6b512f1e98",
            "619a9238e3e043bfaa356a8e1c2473bd",
            "a38c71a4ee7c4c07a8a2ce7e2e231af1",
            "0cf310c7ff194377a8b56774c262bbc6",
            "e6283fd512424a9e9370fbb17f839364",
            "c966f8fbdcbb426ea7107d20bd559575",
            "4a0b8d4cda6640e09f54a50110c47d78",
            "87aa839875c84fe5b339fc071c072f5f",
            "c7c241d11cbe41b29517026ad47d568b",
            "86d2e45f7356449087c6cdcd92d9ca9e",
            "a4e44322a4c846eeb4dbd0aa2cc43e22",
            "f9ec910f86fd4db79eeae5ae9804ce3a",
            "b38661f832f14412b9102940f750bab8",
            "9849feeea2d3402ea2ed1d9d4230eb3e"
          ]
        },
        "id": "SISfVZ0KwlwP",
        "outputId": "d5d20a16-d1f2-48a6-e624-caa6b2f6fc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8271479b57cb4185969aa2da174f3f32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e48942f409c4d8093e53095b21f6c44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4ead6264bf64d53917b767030e3b2f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2aa40c7bfb424e3883616a036ac3b44c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cf310c7ff194377a8b56774c262bbc6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "MAX_SEQ_LENGTH = 2048     # You can choose any value thanks to interal RoPE scaling\n",
        "dtype = None              # None for auto detection\n",
        "load_in_4bit = True       # Use 4bit quantization to reduce memory usage\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-Instruct\",\n",
        "    max_seq_length = MAX_SEQ_LENGTH,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction-tuned models are fine-tuned to follow a specific input template that clearly define the system prompt, the user query and the model's answer. This is particularly useful for conversatioanl agents to define the roles in the chat history.\n",
        "\n",
        "Also for \"one-shot\" instruction dialogues, we must follow such formalism to elicit the model's capabilities and fully exploit its potentialities."
      ],
      "metadata": {
        "id": "gV9uWAC7C-MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msgs = [\n",
        "    {\n",
        "        \"role\" : \"system\",\n",
        "        \"content\" : \"You are a helpful assistant. Your task is to answer the user's questions precisely.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\" : \"user\",\n",
        "        \"content\" : \"If a brick weights 1 kilo plus half a kilo, how much does a brick weigh?\"\n",
        "    },\n",
        "    {\n",
        "        \"role\" : \"assistant\",\n",
        "        \"assistant\" : \"eh, nice question. Gpt-4o doesn't know, how am I supposed to?!\"\n",
        "    }\n",
        "]\n",
        "\n",
        "chat_msgs = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=False)\n",
        "print(chat_msgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qY4A-6_gcd-",
        "outputId": "87965e50-fcc4-4a5c-b35c-396cfd783bae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a helpful assistant. Your task is to answer the user's questions precisely.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "If a brick weights 1 kilo plus half a kilo, how much does a brick weigh?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roles are delimited by some special tags. <mark>Each instruction-tuned LLM has its owns</mark>."
      ],
      "metadata": {
        "id": "C9u7uTMAjFCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We (obviously) don‚Äôt have the model‚Äôs answer for open generation, so we need to leave the assistant field out of the input. However, we must remember to append the assistant tag at the end so that the model can begin generating correctly starting from there."
      ],
      "metadata": {
        "id": "e1iexhqKi2_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msgs = [\n",
        "    {\n",
        "        \"role\" : \"system\",\n",
        "        \"content\" : \"You are a helpful assistant. Your task is to answer the user's questions precisely.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\" : \"user\",\n",
        "        \"content\" : \"If a brick weights 1 kilo plus half a kilo, how much does a brick weigh?\"\n",
        "    },\n",
        "]\n",
        "chat_msgs = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
        "print(chat_msgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSdgNEY_f2dl",
        "outputId": "1faa18e7-acc6-42c1-e7a1-075828d48c93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a helpful assistant. Your task is to answer the user's questions precisely.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "If a brick weights 1 kilo plus half a kilo, how much does a brick weigh?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now evaluate the performances of the base model on a small test sample."
      ],
      "metadata": {
        "id": "XubvUx5e6I0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = dataset[\"test\"].select(range(100))"
      ],
      "metadata": {
        "id": "CR9oz8r20fgr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_configs = {\n",
        "    \"model\" : model,\n",
        "    \"tokenizer\" : tokenizer,\n",
        "    \"dataset\" : test_dataset,\n",
        "    \"batch_size\" : 8,\n",
        "    \"max_new_tokens\" : 64\n",
        "}\n",
        "\n",
        "original_model_summaries = generate_outputs_in_batches(**gen_configs)"
      ],
      "metadata": {
        "id": "0s14Su3QvnUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29f7527-6cc4-46d4-f176-696e525c997f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [01:30<02:12, 16.62s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_txt = test_dataset[\"dialogue\"][10]\n",
        "print(reference_txt)"
      ],
      "metadata": {
        "id": "T4QchFUApAwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(original_model_summaries[10])\n",
        "print(\"-\"*50)\n",
        "print(test_dataset[\"summary\"][10])"
      ],
      "metadata": {
        "id": "7G3qZneAgAG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=test_dataset[\"summary\"],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "print(f\"ORIGINAL MODEL STATS:\")\n",
        "print(original_model_results)"
      ],
      "metadata": {
        "id": "PI_5oh2-zeGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results show how LLMs have already optimal performances in zero-shot contexts. However, without proper prompt tuning to align the model, generations may be ‚Äútoo good‚Äù. LLMs are fine-tuned to satisfy users in terms of clarity and exhaustiveness. These features may, though, interfere with the dataset's style requirements. The take-home message is:\n",
        "> LLMs are no magic potion! We have to learn how to deal with them.\n",
        "\n",
        "\n",
        "The **goal of the training** is not teaching the model to acquire the ability to formulate summaries but rather to **align it to a specif format**."
      ],
      "metadata": {
        "id": "LCQAkMX16PSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now set the training configurations for LoRA."
      ],
      "metadata": {
        "id": "oU1sFDt-6v74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# >> Training arguments\n",
        "SEED = 42\n",
        "\n",
        "# > LoRA\n",
        "R = 16\n",
        "ALPHA = 16\n",
        "LORA_DROPOUT = 0\n",
        "\n",
        "# Train all linear layers in the attention modules\n",
        "TARGET_LAYERS = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "\n",
        "# > Training\n",
        "LR = 2e-4\n",
        "TRAIN_BS=2\n",
        "EVAL_BS=4\n",
        "GRAD_ACC_STEPS=4\n",
        "WARMUP_STEPS=5\n",
        "WEIGHT_DECAY=0.01\n",
        "\n",
        "MAX_STEPS=50"
      ],
      "metadata": {
        "id": "OxfaQjl_XQE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWDvv3yUwlwP"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = R,\n",
        "    target_modules = TARGET_LAYERS,\n",
        "    lora_alpha = ALPHA,\n",
        "    lora_dropout = LORA_DROPOUT, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # for efficiency in gradient backpropagation (uses 30% less VRAM, fits 2x larger batch sizes)\n",
        "    random_state = SEED,\n",
        "    use_rslora = False,  # enable rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall use the `SFTTrainer`, which requires combining input and labels in a unique prompt. For this purpose, we flatten data instances by merging the original text and the target summary using a simple prompt."
      ],
      "metadata": {
        "id": "jNTnL_jg64nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "def flatten_data(example : dict) -> str:\n",
        "    \"\"\"\n",
        "    Combine and prompt data instances by merging the original text and the target summary using a simple prompt.\n",
        "    \"\"\"\n",
        "    msg = [\n",
        "        {\n",
        "            \"role\" : \"system\",\n",
        "            \"content\" : \"You are a helpful assistant. Your task is to summarize the texts provided by the user.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\" : \"user\",\n",
        "            \"content\" : example[\"dialogue\"]\n",
        "        },\n",
        "        {\n",
        "            \"role\" : \"assistant\",\n",
        "            \"content\" : example[\"summary\"]\n",
        "        }\n",
        "    ]\n",
        "    out = {\"text\" : tokenizer.apply_chat_template(msg, tokenize=False, add_generation_prompt=False)}\n",
        "    return out\n",
        "\n",
        "cols = dataset.column_names\n",
        "\n",
        "flatten_ds = DatasetDict({\n",
        "    split : dataset[split].map(flatten_data, remove_columns=cols[split])\n",
        "    for split in dataset\n",
        "})\n",
        "\n",
        "flatten_ds"
      ],
      "metadata": {
        "id": "hfWdEF3SrP1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSb2tqU7wlwP"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "#### 8.4.2 Unsloth Training\n",
        "\n",
        "As we are not interested in fine-tuning the model on the whole text but on the target summary only, we can define a data construct that masks the input up to the start of the text to be generated."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_template = \"assistant<|end_header_id|>\\n\\n\"\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template,\n",
        "                                           tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "ze8zTI2_YzHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In doing so, the model will only learn to generate a summary based on a query. This may seem counterintuitive, but sometimes we want to fine-tune the model using the entire input text. For example, training the model to predict the next token in the question based on the previous ones (this goes under the name of _Continual Pre-Training_)."
      ],
      "metadata": {
        "id": "8FKeQ77KVpLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEEJNZcDwlwP"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = flatten_ds[\"train\"],\n",
        "    eval_dataset = flatten_ds[\"validation\"],\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = MAX_SEQ_LENGTH,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    data_collator=collator,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = TRAIN_BS,\n",
        "        per_device_eval_batch_size = EVAL_BS,\n",
        "        gradient_accumulation_steps = GRAD_ACC_STEPS,\n",
        "        warmup_steps = WARMUP_STEPS,\n",
        "        max_steps = MAX_STEPS,\n",
        "        learning_rate = LR,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = WEIGHT_DECAY,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = SEED,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "LHC6na9H1HbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats"
      ],
      "metadata": {
        "id": "vSXtoYF7f_9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For saving time, you can directly download the fine-tuned model from our Huggingface repository."
      ],
      "metadata": {
        "id": "xgPE4y-pd52n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MAX_SEQ_LENGTH = 2048\n",
        "#dtype = None\n",
        "#\n",
        "#model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#    model_name = \"disi-unibo-nlp/llama3-8B-Instrcut-adapters-dialogsum-lecture\",\n",
        "#    max_seq_length = MAX_SEQ_LENGTH,\n",
        "#    dtype = dtype,\n",
        "#    load_in_4bit = True,\n",
        "#)"
      ],
      "metadata": {
        "id": "sE8v-WMP2wl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_configs = {\n",
        "    \"model\" : model,\n",
        "    \"tokenizer\" : tokenizer,\n",
        "    \"dataset\" : test_dataset,\n",
        "    \"batch_size\" : 8,\n",
        "    \"max_new_tokens\" : 50\n",
        "}\n",
        "\n",
        "instruct_model_summaries = generate_outputs_in_batches(**gen_configs)\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=test_dataset[\"summary\"],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "print(f\"INSTRUCT MODEL STATS:\")\n",
        "print(instruct_model_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXbszeyT4bPx",
        "outputId": "a00c96b5-b1bc-4a59-81bb-781435fa12ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [02:19<00:00, 10.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INSTRUCT MODEL STATS:\n",
            "{'rouge1': 0.4434875664255254, 'rouge2': 0.19104618420594055, 'rougeL': 0.381788311954771, 'rougeLsum': 0.38251384695744994}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ID = 20\n",
        "\n",
        "print(instruct_model_summaries[ID])\n",
        "print(\"-\"*50)\n",
        "print(test_dataset[\"summary\"][ID])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnPtjy8YoCg8",
        "outputId": "16d479be-0b30-4eaf-fdea-dd74e750ad0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Person 2 has symptoms of itching, lightheadedness, and weakness, which may be caused by a rash or an allergy. Person 1 thinks it's chicken pox, which is contagious and potentially serious, especially for adults.\n",
            "--------------------------------------------------\n",
            "#Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ID = 20\n",
        "\n",
        "print(instruct_model_summaries[ID])\n",
        "print(\"-\"*50)\n",
        "print(test_dataset[\"summary\"][ID])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQT_c8GqCMTK",
        "outputId": "40721afb-9d78-45e9-8375-7503c80a57d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person1# thinks #Person2# has chicken pox and #Person2# is contagious.\n",
            "--------------------------------------------------\n",
            "#Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how a short fine-tuning with little data and low computational resources can significantly impact the model's performance."
      ],
      "metadata": {
        "id": "ahsxIvUJB5G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: compare the performance and outpus of a fine-tuned base model\n",
        "\n",
        "You can find here [disi-unibo-nlp/llama3-8B-dialogsum-lecture](https://huggingface.co/disi-unibo-nlp/llama3-8B-dialogsum-lecture) a llama base model finetuned on summarization using the dialogsum dataset.\n",
        "\n",
        "Try to run evaluation on this model --without using the chat template format-- to assess how base models behaves when given an instruction such as \"summarize this text\".\n"
      ],
      "metadata": {
        "id": "oz0-mxl7R0zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO"
      ],
      "metadata": {
        "id": "FfQKLu11UlKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd7lHaRwwlwP"
      },
      "source": [
        "# üèÅ The End!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e88925bf36484e0db791e7494326bb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a701e02fcac549af90641931120cba59",
              "IPY_MODEL_a25005e855844678b317c26910e459fc",
              "IPY_MODEL_57e88807f37e45fcbe8c2cf9dadab5fc"
            ],
            "layout": "IPY_MODEL_3f12bd1c86da4631ab7000ec831630f9"
          }
        },
        "a701e02fcac549af90641931120cba59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b663509e4c18467281213284f1a23a37",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c668cd27725e4217a007a4defea3a6c6",
            "value": "README.md:‚Äá100%"
          }
        },
        "a25005e855844678b317c26910e459fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49b34883443459d89941e3c4f2d55f9",
            "max": 4654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d15d59d04404bf4843d3be612727242",
            "value": 4654
          }
        },
        "57e88807f37e45fcbe8c2cf9dadab5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019cb223c953420883c1dcca34a15899",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ebf76eebd7bf4319bdfb0f7baf8ec1d6",
            "value": "‚Äá4.65k/4.65k‚Äá[00:00&lt;00:00,‚Äá309kB/s]"
          }
        },
        "3f12bd1c86da4631ab7000ec831630f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b663509e4c18467281213284f1a23a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c668cd27725e4217a007a4defea3a6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f49b34883443459d89941e3c4f2d55f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d15d59d04404bf4843d3be612727242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "019cb223c953420883c1dcca34a15899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf76eebd7bf4319bdfb0f7baf8ec1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "babda43599e54acfba0b83b63627cc72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86bed4ab45ef462f8147853f6db31260",
              "IPY_MODEL_3fa93757eee344f39a90bbdee77bcfd3",
              "IPY_MODEL_e0a8d79745454fc7a90d58529da62c88"
            ],
            "layout": "IPY_MODEL_898df6b7419748068b691956924655e1"
          }
        },
        "86bed4ab45ef462f8147853f6db31260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc73841d92341448d22106a6015f166",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_de1a40ef02d046b7bc0d0b9bf97c07ac",
            "value": "train.csv:‚Äá100%"
          }
        },
        "3fa93757eee344f39a90bbdee77bcfd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8d9cb250124d818909694d5f21d41b",
            "max": 11321474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0026e5df70264de1bd095bdc86952f57",
            "value": 11321474
          }
        },
        "e0a8d79745454fc7a90d58529da62c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04e7df021a14d3490622baee7b744aa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_60255df60b7d417bb324e50404d09775",
            "value": "‚Äá11.3M/11.3M‚Äá[00:00&lt;00:00,‚Äá33.0MB/s]"
          }
        },
        "898df6b7419748068b691956924655e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc73841d92341448d22106a6015f166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1a40ef02d046b7bc0d0b9bf97c07ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc8d9cb250124d818909694d5f21d41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0026e5df70264de1bd095bdc86952f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a04e7df021a14d3490622baee7b744aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60255df60b7d417bb324e50404d09775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b750d0d49d646c49f3eb8f2a22272e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_097f5a64be34490683c81dc4a1e23fa3",
              "IPY_MODEL_6850fe780e83435ba572e34e2cef6a45",
              "IPY_MODEL_2d3c087a46cf4661b26eee0d947a5c4b"
            ],
            "layout": "IPY_MODEL_53fe8e9b274b47b3a8e29530b2662577"
          }
        },
        "097f5a64be34490683c81dc4a1e23fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa928bf4bb60453da6fb447da8a14a59",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0f16fb5a985c4fd7a57054b5324d6572",
            "value": "validation.csv:‚Äá100%"
          }
        },
        "6850fe780e83435ba572e34e2cef6a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7006884a2e66499ba3ddc358dfccf61c",
            "max": 441935,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_525ec69ad09248aba6b96c26a7c145d8",
            "value": 441935
          }
        },
        "2d3c087a46cf4661b26eee0d947a5c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c5cfbb7b8d4992ae19610ff31fa335",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eb11591cb25544a9a3eab45c04aa2b50",
            "value": "‚Äá442k/442k‚Äá[00:00&lt;00:00,‚Äá4.79MB/s]"
          }
        },
        "53fe8e9b274b47b3a8e29530b2662577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa928bf4bb60453da6fb447da8a14a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f16fb5a985c4fd7a57054b5324d6572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7006884a2e66499ba3ddc358dfccf61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525ec69ad09248aba6b96c26a7c145d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2c5cfbb7b8d4992ae19610ff31fa335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb11591cb25544a9a3eab45c04aa2b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e49d06bbcd8b482f90aa903e1c70a412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f3cf5455c934448adcb4d07bad6a469",
              "IPY_MODEL_ab438830d549420aada14a1c93fe1d99",
              "IPY_MODEL_494fad0099564bda930ce7b1b458176f"
            ],
            "layout": "IPY_MODEL_a739608c2bd14e7cad6bcc5878488641"
          }
        },
        "2f3cf5455c934448adcb4d07bad6a469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bee9f0834704ad68906cf1a2ae2adfa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_09e49b40f66444da9e6e512375b75cc0",
            "value": "test.csv:‚Äá100%"
          }
        },
        "ab438830d549420aada14a1c93fe1d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e268f4b80624908bce8929c390df0c3",
            "max": 1353147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7338e40f20794077bf6d45534f734c82",
            "value": 1353147
          }
        },
        "494fad0099564bda930ce7b1b458176f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f85ad7840f734554906616adceb34b0f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_01982c7287c4406bb815d9cd2daff0c1",
            "value": "‚Äá1.35M/1.35M‚Äá[00:00&lt;00:00,‚Äá19.2MB/s]"
          }
        },
        "a739608c2bd14e7cad6bcc5878488641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bee9f0834704ad68906cf1a2ae2adfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e49b40f66444da9e6e512375b75cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e268f4b80624908bce8929c390df0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7338e40f20794077bf6d45534f734c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f85ad7840f734554906616adceb34b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01982c7287c4406bb815d9cd2daff0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb17b9ba50c4f0f9df06c0561b6192f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a04fa862d5146f8a9f3cb002b4e0ae0",
              "IPY_MODEL_b1706c84058a42f4bb2a6fd3d157e82b",
              "IPY_MODEL_472a91692c124e88be42def209fe0242"
            ],
            "layout": "IPY_MODEL_5bd7b33cc5904f2796263fc956f93b8e"
          }
        },
        "0a04fa862d5146f8a9f3cb002b4e0ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_844ab54d0925492cba4daa7a5e5aa836",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_239bd5fe2c3645a8a498c794f87d3ff4",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "b1706c84058a42f4bb2a6fd3d157e82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e9615379d94b58bbd69da3fd8b48fa",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0afc45cb9cbb44cb951290995c095378",
            "value": 12460
          }
        },
        "472a91692c124e88be42def209fe0242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_222772e931d9462ca1f97232f8119fe0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0221ef4d7bd7403fa5ac78ba155f2d93",
            "value": "‚Äá12460/12460‚Äá[00:00&lt;00:00,‚Äá27090.40‚Äáexamples/s]"
          }
        },
        "5bd7b33cc5904f2796263fc956f93b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844ab54d0925492cba4daa7a5e5aa836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239bd5fe2c3645a8a498c794f87d3ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2e9615379d94b58bbd69da3fd8b48fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0afc45cb9cbb44cb951290995c095378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "222772e931d9462ca1f97232f8119fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0221ef4d7bd7403fa5ac78ba155f2d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e83016e3726a4c56828a83711daf05cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49fd09e3468f4284ac7a16118fed3bf1",
              "IPY_MODEL_9668cb7963d240e0a5a9953fb268de84",
              "IPY_MODEL_a5b6fa61328745d496b5cd7b09601856"
            ],
            "layout": "IPY_MODEL_36406d33813241f3b3fe7fd15fec5813"
          }
        },
        "49fd09e3468f4284ac7a16118fed3bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_216aa9f8c79e400fb1e29e84e361d353",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9680025a00104e658fd8c0373a501139",
            "value": "Generating‚Äávalidation‚Äásplit:‚Äá100%"
          }
        },
        "9668cb7963d240e0a5a9953fb268de84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1190886eeb248018910f3691d35937d",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a683ce0bf1043e9a56dfb2f0d5b5ce8",
            "value": 500
          }
        },
        "a5b6fa61328745d496b5cd7b09601856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a1d08ed38148719c53b8eb8e884ea8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2224035dd5cf4b4b9b18053f5ce7b6a4",
            "value": "‚Äá500/500‚Äá[00:00&lt;00:00,‚Äá9954.02‚Äáexamples/s]"
          }
        },
        "36406d33813241f3b3fe7fd15fec5813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216aa9f8c79e400fb1e29e84e361d353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9680025a00104e658fd8c0373a501139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1190886eeb248018910f3691d35937d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a683ce0bf1043e9a56dfb2f0d5b5ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63a1d08ed38148719c53b8eb8e884ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2224035dd5cf4b4b9b18053f5ce7b6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01c14d1cedf24450924e615188aff7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_191056bb15584737a0b19d27e35fdcbf",
              "IPY_MODEL_4ea63a987bcc48ed93d116797c639533",
              "IPY_MODEL_d72fb54e7772405dbfe8312c2b5138be"
            ],
            "layout": "IPY_MODEL_ba6fc7067fa143759aa76b3f0c640a88"
          }
        },
        "191056bb15584737a0b19d27e35fdcbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36bd1afaca94691a43304c36348f709",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e7f54468fa6342908de0f64cb4e7db57",
            "value": "Generating‚Äátest‚Äásplit:‚Äá100%"
          }
        },
        "4ea63a987bcc48ed93d116797c639533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84174cd1a2f84d0697f34852457ef287",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6296027f74f6432e9cdc89ad7502b4ae",
            "value": 1500
          }
        },
        "d72fb54e7772405dbfe8312c2b5138be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d6b3d0e12944a596cc637bd97272d0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6861427fe03f456488e523ce7fa48671",
            "value": "‚Äá1500/1500‚Äá[00:00&lt;00:00,‚Äá14517.92‚Äáexamples/s]"
          }
        },
        "ba6fc7067fa143759aa76b3f0c640a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36bd1afaca94691a43304c36348f709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f54468fa6342908de0f64cb4e7db57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84174cd1a2f84d0697f34852457ef287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6296027f74f6432e9cdc89ad7502b4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2d6b3d0e12944a596cc637bd97272d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6861427fe03f456488e523ce7fa48671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8271479b57cb4185969aa2da174f3f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fcf908078e242868efb35465c566aa9",
              "IPY_MODEL_de0f3c47da504181af8f64d8059dfc65",
              "IPY_MODEL_c61fd9461b62464c9f1c6838a74c029f"
            ],
            "layout": "IPY_MODEL_becc8840afaa4dfb8f38f51e032f18d2"
          }
        },
        "1fcf908078e242868efb35465c566aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d25e9d158f044ecbd50a6599156e8a3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a3d8fcc91f9e44a4ac40b0c8dc427128",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "de0f3c47da504181af8f64d8059dfc65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b54a06220f14983855185a6e18b4f31",
            "max": 5702746403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7430332c9bf6429aa97c59163f521ba7",
            "value": 5702746403
          }
        },
        "c61fd9461b62464c9f1c6838a74c029f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1114f5053a40daaed73e404e24e65d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_81e87da1050c4170a0fa96bb48a4522e",
            "value": "‚Äá5.70G/5.70G‚Äá[01:03&lt;00:00,‚Äá52.9MB/s]"
          }
        },
        "becc8840afaa4dfb8f38f51e032f18d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d25e9d158f044ecbd50a6599156e8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d8fcc91f9e44a4ac40b0c8dc427128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b54a06220f14983855185a6e18b4f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7430332c9bf6429aa97c59163f521ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f1114f5053a40daaed73e404e24e65d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e87da1050c4170a0fa96bb48a4522e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e48942f409c4d8093e53095b21f6c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4fc0efbfc344045b92134eadf05a054",
              "IPY_MODEL_c59df812f9ee469d9428aa9ef45f1d61",
              "IPY_MODEL_d894a71a0409440a8f55cbf8d026e243"
            ],
            "layout": "IPY_MODEL_b0c2e0fbd03246a98495b858945ffd4b"
          }
        },
        "d4fc0efbfc344045b92134eadf05a054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1855598c14f4a72a90e7542892b6cbb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8d465c474c354ff28784b18e111687f0",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "c59df812f9ee469d9428aa9ef45f1d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a42eb1ebc01a4fa79f5a7302b8d5be37",
            "max": 220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b32591330724003a46c8ae77cd77582",
            "value": 220
          }
        },
        "d894a71a0409440a8f55cbf8d026e243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_420cff2fe4fc40cc976d70ecd576494e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ada5fe7927234379b6c54d80b988207f",
            "value": "‚Äá220/220‚Äá[00:00&lt;00:00,‚Äá20.2kB/s]"
          }
        },
        "b0c2e0fbd03246a98495b858945ffd4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1855598c14f4a72a90e7542892b6cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d465c474c354ff28784b18e111687f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a42eb1ebc01a4fa79f5a7302b8d5be37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b32591330724003a46c8ae77cd77582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "420cff2fe4fc40cc976d70ecd576494e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ada5fe7927234379b6c54d80b988207f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4ead6264bf64d53917b767030e3b2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f626710ce09438c83001791bdad6bf7",
              "IPY_MODEL_d39cf0ac395f4b4ea537f11811991b86",
              "IPY_MODEL_f089d8561f924ab8a2330421baa648f3"
            ],
            "layout": "IPY_MODEL_a4ca1d91643e4ca5afd4786f475b48c9"
          }
        },
        "4f626710ce09438c83001791bdad6bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_385438e87d2a4767abf524e31422dc2f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d440593cad314701b437f5391adc774c",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "d39cf0ac395f4b4ea537f11811991b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ff1e37449549a1ba575473c85d2693",
            "max": 51052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f2d923722274b98888346a87c34909d",
            "value": 51052
          }
        },
        "f089d8561f924ab8a2330421baa648f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ea473d7874408eaad9ad564299a275",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a0525bd3d86e48959b4b23b50debd18a",
            "value": "‚Äá51.1k/51.1k‚Äá[00:00&lt;00:00,‚Äá4.36MB/s]"
          }
        },
        "a4ca1d91643e4ca5afd4786f475b48c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385438e87d2a4767abf524e31422dc2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d440593cad314701b437f5391adc774c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ff1e37449549a1ba575473c85d2693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2d923722274b98888346a87c34909d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32ea473d7874408eaad9ad564299a275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0525bd3d86e48959b4b23b50debd18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aa40c7bfb424e3883616a036ac3b44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_590e63ff3c834212b5b489755fef80b0",
              "IPY_MODEL_18ac4905e40c458e8c010719a9b98f4b",
              "IPY_MODEL_63136f7ba9134bb4a78081aba2461561"
            ],
            "layout": "IPY_MODEL_a04208e6556f4834a2245204ddd2bbb1"
          }
        },
        "590e63ff3c834212b5b489755fef80b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b485fee302d4b65adc839bbbcff63ba",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f56998a87db6481bb44ef7c53515b1a7",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "18ac4905e40c458e8c010719a9b98f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4664a35431864a1db92ee615102c91a3",
            "max": 9085698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5881ba86c49d4a3e8e71af6b512f1e98",
            "value": 9085698
          }
        },
        "63136f7ba9134bb4a78081aba2461561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_619a9238e3e043bfaa356a8e1c2473bd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a38c71a4ee7c4c07a8a2ce7e2e231af1",
            "value": "‚Äá9.09M/9.09M‚Äá[00:00&lt;00:00,‚Äá35.5MB/s]"
          }
        },
        "a04208e6556f4834a2245204ddd2bbb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b485fee302d4b65adc839bbbcff63ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56998a87db6481bb44ef7c53515b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4664a35431864a1db92ee615102c91a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5881ba86c49d4a3e8e71af6b512f1e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "619a9238e3e043bfaa356a8e1c2473bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a38c71a4ee7c4c07a8a2ce7e2e231af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf310c7ff194377a8b56774c262bbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6283fd512424a9e9370fbb17f839364",
              "IPY_MODEL_c966f8fbdcbb426ea7107d20bd559575",
              "IPY_MODEL_4a0b8d4cda6640e09f54a50110c47d78"
            ],
            "layout": "IPY_MODEL_87aa839875c84fe5b339fc071c072f5f"
          }
        },
        "e6283fd512424a9e9370fbb17f839364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7c241d11cbe41b29517026ad47d568b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_86d2e45f7356449087c6cdcd92d9ca9e",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "c966f8fbdcbb426ea7107d20bd559575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e44322a4c846eeb4dbd0aa2cc43e22",
            "max": 345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9ec910f86fd4db79eeae5ae9804ce3a",
            "value": 345
          }
        },
        "4a0b8d4cda6640e09f54a50110c47d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b38661f832f14412b9102940f750bab8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9849feeea2d3402ea2ed1d9d4230eb3e",
            "value": "‚Äá345/345‚Äá[00:00&lt;00:00,‚Äá33.2kB/s]"
          }
        },
        "87aa839875c84fe5b339fc071c072f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c241d11cbe41b29517026ad47d568b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86d2e45f7356449087c6cdcd92d9ca9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e44322a4c846eeb4dbd0aa2cc43e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ec910f86fd4db79eeae5ae9804ce3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b38661f832f14412b9102940f750bab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9849feeea2d3402ea2ed1d9d4230eb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}